{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetectionTrainer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoshimoto-s/TensorflowObjectAPI_Colab/blob/master/ObjectDetectionTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "y7w2BWvdbQgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Tensorflow Object Detection APIのトレーニングをするためのColabファイルです**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7kD7ccWxum8w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1. 環境の準備"
      ]
    },
    {
      "metadata": {
        "id": "ka9Qsd1UhdI8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Check Environment {display-mode: \"form\"}\n",
        "\n",
        "#GPU環境の確認\n",
        "import platform\n",
        "print(\"python version: \"+platform.python_version())\n",
        "\n",
        "!pip install tensorflow  1>/dev/null\n",
        "#現在のObjectDetectionの対応Tensorflowは1.8らしいんだけど、1.8じゃうまく動かない...\n",
        "import tensorflow as tf;\n",
        "print(\"tensorflow version: \"+tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU not found')\n",
        "print('GPU OK')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUtvgMXSiFUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title ObjectDetectionAPI Installation {display-mode: \"form\"}\n",
        "\n",
        "#install  env\n",
        "print(\"Dependency env installing...\")\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk 1>/dev/null\n",
        "!pip install Cython contextlib2 jupyter pillow lxml matplotlib 1>/dev/null\n",
        "!pip install prompt_toolkit==1.0.15 1>/dev/null\n",
        "!pip install beautifulsoup4 requests 1>/dev/null\n",
        "\n",
        "%cd /content/\n",
        "#特定のコミットを使用する必要があるかもしれない(要検討)\n",
        "print(\"models cloning...\")\n",
        "!git clone https://github.com/tensorflow/models.git &> /dev/null\n",
        "\n",
        "#Cocoapi\n",
        "print(\"coco installing...\")\n",
        "!git clone https://github.com/cocodataset/cocoapi.git &> /dev/null\n",
        "%cd cocoapi/PythonAPI\n",
        "!make &>/dev/null\n",
        "!cp -r pycocotools /content/models/research/\n",
        "\n",
        "#compile protos\n",
        "print(\"proto compiling...\")\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "print(\"Set environ variables\")\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":\"+os.getcwd()\n",
        "os.environ['PYTHONPATH'] += \":\"+os.getcwd()+\"/slim\"\n",
        "\n",
        "print(\"Check environment\")\n",
        "!python object_detection/builders/model_builder_test.py\n",
        "\n",
        "\n",
        "### Other treatment\n",
        "!sed -i -e 's/category_index.values()/list(category_index.values())/' /content/models/research/object_detection/model_lib.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GmwV_HfwvBCb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2. データを準備する"
      ]
    },
    {
      "metadata": {
        "id": "XgjeUmvhv2X0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Google Driveをマウントする"
      ]
    },
    {
      "metadata": {
        "id": "TEt6sD37X1Sf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Mout Google Drive {display-mode: \"form\"}\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sc-oB7aYscm8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "データを格納しているディレクトリを設定する"
      ]
    },
    {
      "metadata": {
        "id": "jwk42fuqsxiI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Set Dataset Dir {display-mode:\"form\"}\n",
        "\n",
        "dataset_dir = 'drive/My Drive/\\u5DE8\\u5927\\u7A4D\\u307F\\u6728/\\u304A\\u53F0\\u5834\\u5B66\\u7FD2\\u30C6\\u3099\\u30FC\\u30BF/2018-05-23' #@param {type: \"string\"}\n",
        "dataset_path = \"/content/\"+dataset_dir\n",
        "\n",
        "import os\n",
        "print(\"copying files...\")\n",
        "os.environ['TF_DATASET_PATH'] = dataset_path\n",
        "!rsync -az --info=progress2 \"$TF_DATASET_PATH\" /content/dataset\n",
        "!echo \"copy files done!\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H8P9jpRtCfiT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ユーティリティを定義する"
      ]
    },
    {
      "metadata": {
        "id": "eM5KPlBZtwJw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Utility Config {display-mode: \"form\"}\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from xml.etree.ElementTree import *\n",
        "import time\n",
        "\n",
        "class Util:\n",
        "    @staticmethod\n",
        "    def GetAvailablePreTrains(path):\n",
        "        graphInfoList = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f == 'pipeline.config':\n",
        "                    graphInfo = {}\n",
        "                    graphInfo['pipeline_path'] = os.path.join(root, f)\n",
        "                    ckpt_list = glob.glob(os.path.join(root, 'model.ckpt*.index'))\n",
        "                    if len(ckpt_list) > 0:\n",
        "                        ckpt_list.sort(key=lambda x: os.path.getmtime(x))\n",
        "                        ckpt_prefix = ckpt_list[-1][:-6]\n",
        "                        graphInfo['checkpoint_path'] = os.path.abspath(ckpt_prefix)\n",
        "                    else:\n",
        "                        ckpt_list = glob.glob(os.path.join(root, '*/model.ckpt*.index'))\n",
        "                        if len(ckpt_list) > 0:\n",
        "                            ckpt_list.sort(key=lambda x: os.path.getmtime(x))\n",
        "                            ckpt_prefix = ckpt_list[-1][:-6]\n",
        "                            graphInfo['checkpoint_path'] = os.path.abspath(ckpt_prefix)\n",
        "\n",
        "                    if('pipeline_path' in graphInfo and 'checkpoint_path' in graphInfo):\n",
        "                        graphInfoList.append(graphInfo)\n",
        "                        #print(\"==============\")\n",
        "                        #print(\"%d\\tpipeline_path:  \\t%s\" % (len(graphInfoList) - 1, graphInfo['pipeline_path']))\n",
        "                        #print(\"  \\tcheckpoint_path:\\t%s\" % (graphInfo['checkpoint_path']))\n",
        "        return graphInfoList\n",
        "\n",
        "    @staticmethod\n",
        "    def GetGraphList(path):\n",
        "        graphInfoList = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f == 'frozen_inference_graph.pb':\n",
        "                    graphInfo = {}\n",
        "                    graphInfo['graph_path'] = os.path.join(root, f)\n",
        "                    graphInfo['label_path'] = os.path.relpath(os.path.join(root, '../labelmap.pbtxt'))\n",
        "                    graphInfoList.append(graphInfo)\n",
        "                    print(\"==============\")\n",
        "                    print(\"%d\\tgraph_path:\\t%s\" % (len(graphInfoList) - 1, graphInfo['graph_path']))\n",
        "                    print(\"  \\tlabel_path:\\t%s\" % (graphInfo['label_path']))\n",
        "        return graphInfoList\n",
        "\n",
        "    @staticmethod\n",
        "    def GetLabels(path):\n",
        "        labels = []\n",
        "        xml_files = Util.GetXmlFiles(path)\n",
        "        for i,f in enumerate(xml_files):\n",
        "            if i % 10 == 9 or (i + 1 == len(xml_files)):\n",
        "                print(\"\\r>> Analizing...%d/%d\" % (i + 1, len(xml_files)), end='', flush=True)\n",
        "            tree = parse(f) \n",
        "            elem = tree.getroot()\n",
        "            for n in elem.findall(\".//name\"):\n",
        "                if n.text not in labels:\n",
        "                    labels.append(n.text)\n",
        "        print(\"\")\n",
        "        return labels\n",
        "\n",
        "    @staticmethod\n",
        "    def GetXmlFiles(path):\n",
        "        xml_files = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f.lower().endswith('.xml'):\n",
        "                    xml_files.append(os.path.relpath(os.path.join(root,f)))\n",
        "        return xml_files\n",
        "\n",
        "    @staticmethod\n",
        "    def GetJPEGFiles(path):\n",
        "        jpg_files = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f.lower().endswith('.jpg'):\n",
        "                    jpg_files.append(os.path.relpath(os.path.join(root,f)))\n",
        "        return jpg_files\n",
        "    \n",
        "print(\"Util Define Done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xUhzIrSoCmBp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ラベル情報を取得する"
      ]
    },
    {
      "metadata": {
        "id": "MQI_V_USBRqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "labels = Util.GetLabels(\"/content/dataset\")\n",
        "\n",
        "print(\"elapsed_time:%.3f[sec]\" % (time.time() - start))\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11kw0W0ICVNq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ラベリングのミスとかあったら、下記コマンドで一括修正する\n",
        "#!find /content/dataset  -type f -name \"*.xml\" | xargs sed -i -e 's/before/after/g'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uKqijCaYDbGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "データを学習用とテスト用に分ける"
      ]
    },
    {
      "metadata": {
        "id": "GjTL2CMVERGX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title TFRecord Util {display-mode: \"form\"}\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from PIL import Image\n",
        "from xml.etree.ElementTree import *\n",
        "import time\n",
        "from object_detection.protos import string_int_label_map_pb2\n",
        "#import contextlib2\n",
        "#from google3.third_party.tensorflow_models.object_detection.dataset_tools import tf_record_creation_util\n",
        "\n",
        "def create_tf_record(xml_list, class_list, output_path):\n",
        "    start = time.time()\n",
        "    writer = tf.python_io.TFRecordWriter(output_path)\n",
        "    class_num_list = {}\n",
        "    for cn in class_list:\n",
        "        class_num_list[cn] = 0\n",
        "    ignoreCount = 0;\n",
        "    for i,f in enumerate(xml_list):\n",
        "        if i % 10 == 9 or (i + 1 == len(xml_list)):\n",
        "            print(\"\\r>> Converting...%d/%d\" % (i + 1, len(xml_list)), end='', flush=True)\n",
        "            \n",
        "        tf_example = create_tf_example(f, class_list, class_num_list)\n",
        "        if(tf_example != None):\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "        else:\n",
        "            ignoreCount += 1\n",
        "    writer.close()\n",
        "    print(\"TFRecord convert done...%d\" % len(xml_list)) \n",
        "    if ignoreCount > 0:\n",
        "        print(\"%d files ignored\" % ignoreCount)\n",
        "    print(\"-----Label counts-----\")\n",
        "    for k,v in class_num_list.items():\n",
        "        print(k + \": \" + str(v))\n",
        "    elapsed_time = time.time() - start\n",
        "    print(\"elapsed_time:%.3f[sec]\" % elapsed_time)\n",
        "    \n",
        "    #ここより先は気が向いたら実装する\n",
        "    #num_shards=10\n",
        "    #output_filebase='/path/to/train_dataset.record'\n",
        "\n",
        "    #with contextlib2.ExitStack() as tf_record_close_stack:\n",
        "        #output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
        "        #tf_record_close_stack, output_filebase, num_shards)\n",
        "        #for index, example in examples:\n",
        "            #tf_example = create_tf_example(example)\n",
        "            #output_shard_index = index % num_shards\n",
        "            #output_tfrecords[output_shard_index].write(tf_example.SerializeToString())\n",
        "    \n",
        "\n",
        "def create_tf_example(xml_path, class_list, class_num_list):\n",
        "    img_path = os.path.abspath(os.path.dirname(xml_path) + \"/../JPEGImages\") + \"/\" + os.path.basename(xml_path).replace('.xml','.jpg')\n",
        "    if(not os.path.exists(img_path)):\n",
        "        return None\n",
        "    \n",
        "    img = Image.open(img_path)\n",
        "    height = img.size[1] # Image height\n",
        "    width = img.size[0] # Image width\n",
        "    #filename = img_path # Filename of the image. Empty if image is not from file\n",
        "    filename = b'' # Filename of the image. Empty if image is not from file\n",
        "    encoded_image_data = None # Encoded image bytes\n",
        "    image_format = b'jpeg' # b'jpeg' or b'png'\n",
        "    \n",
        "    with tf.gfile.GFile(img_path,'rb') as fid:\n",
        "        encoded_image_data = fid.read()\n",
        "    \n",
        "\n",
        "    xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
        "    xmaxs = [] # List of normalized right x coordinates in bounding box  (1 per box)\n",
        "    ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
        "    ymaxs = [] # List of normalized bottom y coordinates in bounding box (1 per box)\n",
        "    classes_text = [] # List of string class name of bounding box (1 per box)\n",
        "    classes = [] # List of integer class id of bounding box (1 per box)\n",
        "    \n",
        "    tree = parse(xml_path)\n",
        "    elem = tree.getroot()\n",
        "\n",
        "    for obj in elem.getiterator(\"object\"):\n",
        "        name = obj.find(\"name\").text\n",
        "        bndbox = obj.find(\"bndbox\")\n",
        "        xmin = bndbox.find(\"xmin\").text\n",
        "        xmax = bndbox.find(\"xmax\").text\n",
        "        ymin = bndbox.find(\"ymin\").text\n",
        "        ymax = bndbox.find(\"ymax\").text\n",
        "        classes_text.append(name.encode())\n",
        "        classes.append(class_list.index(name) + 1)\n",
        "        xmins.append(float(xmin) / width)\n",
        "        ymins.append(float(ymin) / height)\n",
        "        xmaxs.append(float(xmax) / width)\n",
        "        ymaxs.append(float(ymax) / height)\n",
        "        class_num_list[name] += 1\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image/height': dataset_util.int64_feature(height),\n",
        "      'image/width': dataset_util.int64_feature(width),\n",
        "      'image/filename': dataset_util.bytes_feature(filename),\n",
        "      'image/source_id': dataset_util.bytes_feature(filename),\n",
        "      'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
        "      'image/format': dataset_util.bytes_feature(image_format),\n",
        "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "from google.protobuf import text_format\n",
        "\n",
        "def create_labelmap(labels, output_path):\n",
        "    label_config = string_int_label_map_pb2.StringIntLabelMap()\n",
        "    for i,l in enumerate(labels):\n",
        "        item = label_config.item.add()\n",
        "        item.name = l\n",
        "        item.id = i+1\n",
        "        item.display_name = l\n",
        "    \n",
        "    labels_text = text_format.MessageToString(label_config)\n",
        "    with tf.gfile.Open(output_path, \"wb\") as f:\n",
        "        f.write(labels_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ErfT5WGtDW6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "xml_files = Util.GetXmlFiles(\"/content/dataset\")\n",
        "\n",
        "#全体の80%を学習用、20%を評価用に使う\n",
        "train_data_rate = 0.8\n",
        "random.shuffle(xml_files)\n",
        "split_num = int(len(xml_files) * train_data_rate)\n",
        "train_xml_files = xml_files[:split_num]\n",
        "test_xml_files = xml_files[split_num:]\n",
        "\n",
        "!mkdir -p /content/tfrecords\n",
        "create_tf_record(train_xml_files, labels, \"/content/tfrecords/train.record\")\n",
        "create_tf_record(test_xml_files, labels, \"/content/tfrecords/test.record\")\n",
        "create_labelmap(labels, \"/content/tfrecords/labelmap.pbtxt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wbKgtGd61mfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3. モデルを準備する"
      ]
    },
    {
      "metadata": {
        "id": "L0j5ehSx-A1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "環境の準備"
      ]
    },
    {
      "metadata": {
        "id": "eAhpxAGC3LuR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title List Available Models {display-mode: \"form\"}\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "r = requests.get(\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\")\n",
        "soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "model_list = {}\n",
        "for i,a in enumerate(soup.select('a[href^=\"http://download.tensorflow.org/models/object_detection/\"]')):\n",
        "    model_list[a.get_text()] = a.get('href')\n",
        "\n",
        "    \n",
        "#ローカルで学習させた奴も増えて来る予定なので、それはここに追加していく    \n",
        "\n",
        "model_name = \"\"\n",
        "# Display List \n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "def set_model_list():\n",
        "    with output.redirect_to_element(\"#items\"):\n",
        "        for v,k in model_list.items():\n",
        "            display(IPython.display.HTML('<li><ahref=\"javascript:void(0)\" onclick=''setModel(\"'+v+'\")''>'+v+'</a></li>'))\n",
        "                                         \n",
        "def set_model(name):\n",
        "    os.environ['TF_MODEL_URL'] = model_list[name]\n",
        "    os.environ['TF_MODEL_NAME'] = name\n",
        "    print(name + \" is selected\")\n",
        "    \n",
        "output.register_callback('notebook.ShowModelList', set_model_list)\n",
        "output.register_callback('notebook.SetModel', set_model)\n",
        "display(IPython.display.HTML('''\n",
        "    Models:\n",
        "    <br>\n",
        "    <ol id=\"items\"></ol>\n",
        "    <style type=\"text/css\">\n",
        "    <!--\n",
        "    li {color:blue; line-height:1.5;cursor : pointer;text-decoration: underline;}\n",
        "    -->\n",
        "    </style>\n",
        "    <script>\n",
        "        google.colab.kernel.invokeFunction('notebook.ShowModelList', [], {});\n",
        "        \n",
        "        function setModel(name) {\n",
        "            google.colab.kernel.invokeFunction('notebook.SetModel', [name], {});\n",
        "        }\n",
        "    </script>\n",
        "    '''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kn6QDvSV6dRd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/pretrained_model/\n",
        "\n",
        "%cd /content/pretrained_model\n",
        "!wget $TF_MODEL_URL &> /dev/null\n",
        "!tar xzvf *.tar.gz &> /dev/null\n",
        "\n",
        "%cd /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YKPmgDVTOGvf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4. 学習の設定をする"
      ]
    },
    {
      "metadata": {
        "id": "QTfSM-fPONrL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/work\n",
        "\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from object_detection.utils import config_util\n",
        "\n",
        "models = Util.GetAvailablePreTrains(\"/content/pretrained_model\")\n",
        "\n",
        "config_path = \"/content/models/research/object_detection/samples/configs/\"+os.environ[\"TF_MODEL_NAME\"] +\".config\"\n",
        "\n",
        "if os.path.exists(config_path):\n",
        "    print(\"use samples/configs/**\")\n",
        "else:\n",
        "    print(\"use model included config\")\n",
        "    config_path = models[0]['pipeline_path']\n",
        "\n",
        "config = config_util.get_configs_from_pipeline_file(config_path)\n",
        "\n",
        "if(config['model'].HasField('ssd')):\n",
        "    config['model'].ssd.num_classes = len(labels)\n",
        "elif(config['model'].HasField('faster_rcnn')):\n",
        "    config['model'].faster_rcnn.num_classes = len(labels)\n",
        "\n",
        "config[\"train_config\"].fine_tune_checkpoint = models[0]['checkpoint_path']\n",
        "config[\"train_input_config\"].label_map_path = \"/content/tfrecords/labelmap.pbtxt\"\n",
        "config[\"train_input_config\"].tf_record_input_reader.input_path.pop()\n",
        "config[\"train_input_config\"].tf_record_input_reader.input_path.append(\"/content/tfrecords/train.record\")\n",
        "config[\"eval_input_config\"].label_map_path = \"/content/tfrecords/labelmap.pbtxt\"\n",
        "config[\"eval_input_config\"].tf_record_input_reader.input_path.pop()\n",
        "config[\"eval_input_config\"].tf_record_input_reader.input_path.append(\"/content/tfrecords/test.record\")\n",
        "\n",
        "pipeline = config_util.create_pipeline_proto_from_configs(config)\n",
        "config_util.save_pipeline_config(pipeline, \"/content/work\")\n",
        "\n",
        "#!cat /content/work/pipeline.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4exvljM5DPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#もしpipeline.configを手動でいじりたかったら、左のファイルリストから/work/pipeline.configをダウンロードして、上書きしてね"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o_5sQLPY_Qbc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5. 学習の実行"
      ]
    },
    {
      "metadata": {
        "id": "qnCkD79pybzX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Run Tensorboard {display-mode: \"form\"}\n",
        "from subprocess import Popen\n",
        "from time import sleep \n",
        "\n",
        "print(\"tensorboard run...\")\n",
        "cmd = \"tensorboard --logdir /content/work/ --host 0.0.0.0 --port 6006\"\n",
        "proc = Popen( cmd,shell=True )\n",
        "#2重起動しない仕組みいれないとなー\n",
        "\n",
        "sleep(5)\n",
        "\n",
        "!mkdir -p /content/ngrok\n",
        "%cd /content/ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip &>/dev/null\n",
        "!unzip *.zip &>/dev/null\n",
        "\n",
        "print(\"ngrok run...\")\n",
        "cmd = \"./ngrok http 6006\"\n",
        "proc = Popen( cmd , shell=True)\n",
        "#2重起動しない仕組みいれないとなー\n",
        "\n",
        "sleep(5)\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import qrcode\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as npj\n",
        "import os.path\n",
        "\n",
        "res = requests.get('http://localhost:4040')\n",
        "import re\n",
        "#print(res.text)\n",
        "m = re.search(r\"(https:\\/\\/.*?ngrok.io)\", res.text)\n",
        "if m:\n",
        "    print(\"Watch runing status bellow\")\n",
        "    url = m.group(1)\n",
        "    print(url)\n",
        "    img = qrcode.make(url)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HZvFAgwqxrVs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習を実行！！"
      ]
    },
    {
      "metadata": {
        "id": "pyEozutn5tws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!sed -i -e 's/category_index.values()/list(category_index.values())/' /content/models/research/object_detection/model_lib.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3WNNj41XzR2O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "!python object_detection/model_main.py  \\\n",
        "            --pipeline_config_path=/content/work/pipeline.config \\\n",
        "            --model_dir=/content/work/log \\\n",
        "            --num_train_steps=50000 \\\n",
        "            --sample_1_of_n_eval_examples=1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6yX9UvdjC867",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#pipelineファイルの中身をみたければ...\n",
        "#!cat /content/work/pipeline.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uVJPtRMp9m7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 6. 学習データをエクスポートする"
      ]
    },
    {
      "metadata": {
        "id": "NdYwxuQ69sFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6Ldtf9e-kHB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Appendix SandBox"
      ]
    },
    {
      "metadata": {
        "id": "a2EPra62-omN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#学習プロセスが動いているか確認\n",
        "!ps auxf | grep model_main | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7Z52C-p8qha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep tensorboard | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AhJyLky81xH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep ngrok | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p-wrWsKt-y-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#学習ログを削除\n",
        "!rm -rf /content/work/log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KDqdMgazAX49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#直接学習実行\n",
        "%cd /content/models/research\n",
        "!python2 object_detection/model_main.py  \\\n",
        "            --pipeline_config_path=/content/work/pipeline.config \\\n",
        "            --model_dir=/content/work/log \\\n",
        "            --num_train_steps=50000 \\\n",
        "            --sample_1_of_n_eval_examples=1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uVpnVzJcDhsS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf /content/ngrok"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JMaYIesI879J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/work/log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xvMBOK7y9zyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from subprocess import Popen\n",
        "cmd = \"while sleep 10; do rsync -a /content/work/log /content/test; done\"\n",
        "proc = Popen( cmd,shell=True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TIjTcDa1-yC9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!echo \"test\" >> /content/work/log/test.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "btA99vQE-_rY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "603c6904-5288-4764-8441-a9cdbf1e0cf5"
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep while"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root         705  0.0  0.0  34304  4736 ?        S    03:21   0:00 /bin/sh -c while sleep 10; do rsync -a /content/work/log /content/test; done\n",
            "root         721  0.0  0.0  39196  6572 ?        S    03:22   0:00 /bin/bash -c ps aux | grep while\n",
            "root         723  0.0  0.0  38568  5548 ?        S    03:22   0:00 grep while\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mKTj2tUV_Ef1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ee391ad-abe7-4927-ab10-536a5d19f001"
      },
      "cell_type": "code",
      "source": [
        "!while sleep 10; do rsync -a /content/work/log /content/test"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KZZ0AOgY_Ju1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!echo \"test aaaa\" >> /content/work/log/test2.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MNjMDiIm_ehq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}