{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetectionTrainer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoshimoto-s/TensorflowObjectAPI_Colab/blob/master/ObjectDetectionTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "y7w2BWvdbQgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Tensorflow Object Detection APIのトレーニングをするためのColabファイルです**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7kD7ccWxum8w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1. 環境の準備"
      ]
    },
    {
      "metadata": {
        "id": "ax29Z6Ha0rEt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "環境のチェック  \n",
        "[GPU OK] が出てくれば大丈夫！"
      ]
    },
    {
      "metadata": {
        "id": "ka9Qsd1UhdI8",
        "colab_type": "code",
        "outputId": "f47b1fe2-080c-4d77-a9b3-197510b0fd64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Check Environment {display-mode: \"form\"}\n",
        "\n",
        "#GPU環境の確認\n",
        "import platform\n",
        "print(\"python version: \"+platform.python_version())\n",
        "\n",
        "!pip install tensorflow  1>/dev/null\n",
        "#現在のObjectDetectionの対応Tensorflowは1.8らしいんだけど、1.8じゃうまく動かない...\n",
        "import tensorflow as tf;\n",
        "print(\"tensorflow version: \"+tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU not found')\n",
        "    print('ランタイムの設定がGPUになっていることを確認してください')\n",
        "print('GPU OK')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python version: 3.6.7\n",
            "tensorflow version: 1.13.1\n",
            "GPU OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L5M_bcGu05xf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "環境作成がうまく行ったか確認 最後に [OK]が出れば大丈夫"
      ]
    },
    {
      "metadata": {
        "id": "jUtvgMXSiFUg",
        "colab_type": "code",
        "outputId": "b5cd7650-c248-43b4-d675-680d849a244d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "#@title ObjectDetectionAPI Installation {display-mode: \"form\"}\n",
        "\n",
        "#install  env\n",
        "print(\"Dependency env installing...\")\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk 1>/dev/null\n",
        "!pip install Cython contextlib2 jupyter pillow lxml matplotlib 1>/dev/null\n",
        "!pip install prompt_toolkit==1.0.15 1>/dev/null\n",
        "\n",
        "%cd /content/\n",
        "#特定のコミットを使用する必要があるかもしれない(要検討)\n",
        "print(\"models cloning...\")\n",
        "!git clone https://github.com/tensorflow/models.git &> /dev/null\n",
        "\n",
        "#Cocoapi\n",
        "print(\"coco installing...\")\n",
        "!git clone https://github.com/cocodataset/cocoapi.git &> /dev/null\n",
        "%cd cocoapi/PythonAPI\n",
        "!make &>/dev/null\n",
        "!cp -r pycocotools /content/models/research/\n",
        "\n",
        "#compile protos\n",
        "print(\"proto compiling...\")\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "print(\"Set environ variables\")\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":\"+os.getcwd()\n",
        "os.environ['PYTHONPATH'] += \":\"+os.getcwd()+\"/slim\"\n",
        "\n",
        "### Other treatment\n",
        "!sed -i -e 's/category_index.values()/list(category_index.values())/' /content/models/research/object_detection/model_lib.py\n",
        "\n",
        "### Other requirment\n",
        "!pip install beautifulsoup4 requests 1>/dev/null\n",
        "!pip install qrcode 1>/dev/null\n",
        "\n",
        "print(\"Check environment\")\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dependency env installing...\n",
            "\u001b[31mipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
            "/content\n",
            "models cloning...\n",
            "coco installing...\n",
            "/content/cocoapi/PythonAPI\n",
            "proto compiling...\n",
            "/content/models/research\n",
            "Set environ variables\n",
            "Check environment\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "............s...\n",
            "----------------------------------------------------------------------\n",
            "Ran 16 tests in 0.069s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GmwV_HfwvBCb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2. データを準備する"
      ]
    },
    {
      "metadata": {
        "id": "fO5INN2D1OYU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "必要なUtilityを定義します"
      ]
    },
    {
      "metadata": {
        "id": "eM5KPlBZtwJw",
        "colab_type": "code",
        "outputId": "77d7b3b0-ae0a-4209-9f5a-ef578b795675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Utility Config {display-mode: \"form\"}\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from xml.etree.ElementTree import *\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Util:\n",
        "    @staticmethod\n",
        "    def GetAvailablePreTrains(path):\n",
        "        graphInfoList = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f == 'pipeline.config':\n",
        "                    graphInfo = {}\n",
        "                    graphInfo['pipeline_path'] = os.path.join(root, f)\n",
        "                    ckpt_list = glob.glob(os.path.join(root, 'model.ckpt*.index'))\n",
        "                    if len(ckpt_list) > 0:\n",
        "                        ckpt_list.sort(key=lambda x: os.path.getmtime(x))\n",
        "                        ckpt_prefix = ckpt_list[-1][:-6]\n",
        "                        graphInfo['checkpoint_path'] = os.path.abspath(ckpt_prefix)\n",
        "                    else:\n",
        "                        ckpt_list = glob.glob(os.path.join(root, '*/model.ckpt*.index'))\n",
        "                        if len(ckpt_list) > 0:\n",
        "                            ckpt_list.sort(key=lambda x: os.path.getmtime(x))\n",
        "                            ckpt_prefix = ckpt_list[-1][:-6]\n",
        "                            graphInfo['checkpoint_path'] = os.path.abspath(ckpt_prefix)\n",
        "\n",
        "                    if('pipeline_path' in graphInfo and 'checkpoint_path' in graphInfo):\n",
        "                        graphInfoList.append(graphInfo)\n",
        "                        #print(\"==============\")\n",
        "                        #print(\"%d\\tpipeline_path:  \\t%s\" % (len(graphInfoList) - 1, graphInfo['pipeline_path']))\n",
        "                        #print(\"  \\tcheckpoint_path:\\t%s\" % (graphInfo['checkpoint_path']))\n",
        "        return graphInfoList\n",
        "\n",
        "    @staticmethod\n",
        "    def GetGraphList(path):\n",
        "        graphInfoList = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f == 'frozen_inference_graph.pb':\n",
        "                    graphInfo = {}\n",
        "                    graphInfo['graph_path'] = os.path.join(root, f)\n",
        "                    graphInfo['label_path'] = os.path.relpath(os.path.join(root, '../labelmap.pbtxt'))\n",
        "                    graphInfoList.append(graphInfo)\n",
        "                    print(\"==============\")\n",
        "                    print(\"%d\\tgraph_path:\\t%s\" % (len(graphInfoList) - 1, graphInfo['graph_path']))\n",
        "                    print(\"  \\tlabel_path:\\t%s\" % (graphInfo['label_path']))\n",
        "        return graphInfoList\n",
        "\n",
        "    @staticmethod\n",
        "    def GetLabels(path):\n",
        "        labels = []\n",
        "        xml_files = Util.GetXmlFiles(path)\n",
        "        for f in tqdm(xml_files):\n",
        "            try:\n",
        "                tree = parse(f) \n",
        "                elem = tree.getroot()\n",
        "                for n in elem.findall(\".//name\"):\n",
        "                    if n.text not in labels:\n",
        "                        labels.append(n.text)\n",
        "            except:\n",
        "                print(\"read error %s\" % f)\n",
        "        print(\"\",flush=True)\n",
        "        return labels\n",
        "\n",
        "    @staticmethod\n",
        "    def GetXmlFiles(path):\n",
        "        xml_files = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f.lower().endswith('.xml'):\n",
        "                    xml_files.append(os.path.relpath(os.path.join(root,f)))\n",
        "        return xml_files\n",
        "\n",
        "    @staticmethod\n",
        "    def GetJPEGFiles(path):\n",
        "        jpg_files = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f.lower().endswith('.jpg'):\n",
        "                    jpg_files.append(os.path.relpath(os.path.join(root,f)))\n",
        "        return jpg_files\n",
        "print(\"Util Define Done\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Util Define Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TEt6sD37X1Sf",
        "colab_type": "code",
        "outputId": "acece073-f6a7-4dcf-cc43-6aa1661848a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive {display-mode: \"form\"}\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GjTL2CMVERGX",
        "colab_type": "code",
        "outputId": "7337e395-4eb2-4528-a24f-402e50e9b1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title TFRecord Util {display-mode: \"form\"}\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from PIL import Image\n",
        "from xml.etree.ElementTree import *\n",
        "import time\n",
        "from object_detection.protos import string_int_label_map_pb2\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import json\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import contextlib2\n",
        "import math\n",
        "from object_detection.dataset_tools import tf_record_creation_util\n",
        "from io import BytesIO \n",
        "\n",
        "max_num_per_tfrecord = 5000\n",
        "max_examples = 50000\n",
        "\n",
        "def create_tf_record_labelBox(json_url, order, train_ratio, output_path):\n",
        "    res = requests.get(json_url)\n",
        "    json_dict = json.loads(res.text)\n",
        "    categories = []\n",
        "    images = []\n",
        "    \n",
        "    categories = []\n",
        "    images = []\n",
        "    annotations = []\n",
        "    for data in json_dict:\n",
        "        if data['Label'] != 'Skip':\n",
        "            objNum = 0\n",
        "            for label in data['Label']:\n",
        "                objNum += len(data['Label'][label])\n",
        "                if label not in categories:\n",
        "                    categories.append(label)\n",
        "            if objNum > 0:\n",
        "                images.append(data['Labeled Data'])\n",
        "                annotations.append(data['Label'])\n",
        "                    \n",
        "    labels = categories\n",
        "    split_num = int(len(images) * train_ratio)\n",
        "    train_images = images[:split_num]\n",
        "    train_annos = annotations[:split_num]\n",
        "    test_images = images[split_num:]\n",
        "    test_annos = annotations[split_num:]\n",
        "    \n",
        "    print(\"\",flush=True)\n",
        "    print(\"----Creating Train Data\", flush=True)\n",
        "    create_tf_record_from_json_dict(train_images, train_annos, labels, os.path.join(output_path,\"train.record\"))\n",
        "    print(\"----Creating Test Data\", flush=True)\n",
        "    create_tf_record_from_json_dict(test_images, test_annos, labels, os.path.join(output_path,\"test.record\"))\n",
        "    create_labelmap(labels, os.path.join(output_path, \"labelmap.pbtxt\"))\n",
        "    print(\"TF Record Creation Complete.\")\n",
        "    return labels\n",
        "    \n",
        "def create_tf_record_from_json_dict(images, annotations, label_list, output_path):\n",
        "    class_list = {}\n",
        "    for i,l in enumerate(label_list):\n",
        "        class_list[l] = {\"id\":i+1, \"num\":0}\n",
        "    if len(images) > max_examples:\n",
        "        images = images[0:max_examples]\n",
        "    #writer = tf.python_io.TFRecordWriter(output_path)\n",
        "    num_shards = math.ceil(len(images) / max_num_per_tfrecord)\n",
        "    with contextlib2.ExitStack() as tf_record_close_stack:\n",
        "        output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
        "        tf_record_close_stack, output_path, num_shards)\n",
        "        for i, img in enumerate(tqdm(images)):\n",
        "            output_shard_index = i % num_shards\n",
        "            \n",
        "            #id = img[\"id\"]\n",
        "            #url = img[\"file_name\"]\n",
        "            res = requests.get(img)\n",
        "            encoded_image_data = res.content\n",
        "            pimg = Image.open(BytesIO(encoded_image_data))\n",
        "            width, height = pimg.size\n",
        "            filename = b''\n",
        "            image_format = b'jpeg'\n",
        "            \n",
        "            xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
        "            xmaxs = [] # List of normalized right x coordinates in bounding box  (1 per box)\n",
        "            ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
        "            ymaxs = [] # List of normalized bottom y coordinates in bounding box (1 per box)\n",
        "            classes_text = [] # List of string class name of bounding box (1 per box)\n",
        "            classes = [] # List of integer class id of bounding box (1 per box)\n",
        "            annos = annotations[i]\n",
        "            for cat in annos:\n",
        "                for geo in annos[cat]:\n",
        "                    xmin = width -1\n",
        "                    ymin = height -1\n",
        "                    xmax = 0\n",
        "                    ymax = 0\n",
        "                    for p in geo['geometry']:\n",
        "                        p['x'] = min(width-1, max(0, p['x']))\n",
        "                        p['y'] = min(height-1, max(0, p['y']))\n",
        "                        xmin = min(p['x'], xmin)\n",
        "                        ymin = min(p['y'], ymin)\n",
        "                        xmax = max(p['x'], xmax)\n",
        "                        ymax = max(p['y'], ymax)\n",
        "                        \n",
        "                    if (xmax - xmin) * (ymax - ymin) > 0:\n",
        "                        xmins.append(float(xmin) / width)\n",
        "                        ymins.append(float(ymin) / height)\n",
        "                        xmaxs.append(float(xmax) / width)\n",
        "                        ymaxs.append(float(ymax) / height)\n",
        "                        name = cat\n",
        "                        classes_text.append(name.encode())\n",
        "                        classes.append(class_list[name][\"id\"])\n",
        "                        class_list[name][\"num\"] += 1\n",
        "                    \n",
        "            tf_example = create_tf_example(filename, width, height, \n",
        "                                 encoded_image_data, image_format,\n",
        "                                 xmins, xmaxs, ymins, ymaxs, classes_text, classes)\n",
        "            output_tfrecords[output_shard_index].write(tf_example.SerializeToString())\n",
        "        \n",
        "        print(\"\",flush=True)\n",
        "        print(\"TFRecord convert done...%d\" % len(images)) \n",
        "        print(\"-----Label counts-----\")\n",
        "        for k,v in class_list.items():\n",
        "            print(k + \": \" + str(v[\"num\"]))\n",
        "    \n",
        "def create_tf_record_labelImage(input_dir, order, train_ratio, output_path): \n",
        "    xml_files = Util.GetXmlFiles(input_dir)\n",
        "    labels = Util.GetLabels(input_dir)\n",
        "    if order == \"random\":\n",
        "        random.shuffle(xml_files)\n",
        "    elif order == \"date\":\n",
        "        xml_files.sort(key=lambda f: int(filter(str.isdigit, os.path.basename(f))))\n",
        "    split_num = int(len(xml_files) * train_ratio)\n",
        "    train_xml_files = xml_files[:split_num]\n",
        "    test_xml_files = xml_files[split_num:]\n",
        "\n",
        "    print(\"\",flush=True)\n",
        "    print(\"----Creating Train Data\", flush=True)\n",
        "    create_tf_record_from_xml_list(train_xml_files, labels, os.path.join(output_path,\"train.record\"))\n",
        "    print(\"----Creating Test Data\", flush=True)\n",
        "    create_tf_record_from_xml_list(test_xml_files, labels, os.path.join(output_path, \"test.record\"))\n",
        "    create_labelmap(labels, os.path.join(output_path, \"labelmap.pbtxt\"))\n",
        "    print(\"TF Record Creation Complete.\", flush=True)\n",
        "    return labels\n",
        "\n",
        "def create_tf_record_from_xml_list(xml_list, label_list, output_path):\n",
        "    class_list = {}\n",
        "    for i,l in enumerate(label_list):\n",
        "        class_list[l] = {\"id\":i+1, \"num\":0}\n",
        "        \n",
        "    if len(xml_list) > max_examples:\n",
        "        xml_list = xml_list[0:max_examples]\n",
        "    ignoreCount = 0\n",
        "    num_shards = math.ceil(len(xml_list) / max_num_per_tfrecord)\n",
        "    with contextlib2.ExitStack() as tf_record_close_stack:\n",
        "        output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
        "        tf_record_close_stack, output_path, num_shards)\n",
        "        for i, f in enumerate(tqdm(xml_list)):\n",
        "            tf_example =create_tf_example_labelImage(f, class_list)\n",
        "            if tf_example != None:\n",
        "                output_shard_index = i % num_shards\n",
        "                output_tfrecords[output_shard_index].write(tf_example.SerializeToString())\n",
        "            else:\n",
        "                ignoreCount += 1\n",
        "    \n",
        "    #writer.close()\n",
        "    print(\"\",flush=True)\n",
        "    print(\"TFRecord convert done...%d\" % len(xml_list)) \n",
        "    if ignoreCount > 0:\n",
        "        print(\"%d files ignored\" % ignoreCount)\n",
        "    print(\"-----Label counts-----\")\n",
        "    for k,v in class_list.items():\n",
        "        print(k + \": \" + str(v[\"num\"]))\n",
        "        \n",
        "\n",
        "def create_tf_example_labelImage(xml_path,  class_list):\n",
        "    img_path = os.path.abspath(os.path.dirname(xml_path) + \"/../JPEGImages\") + \"/\" + os.path.basename(xml_path).replace('.xml','.jpg')\n",
        "    if(not os.path.exists(img_path)):\n",
        "        return None\n",
        "    \n",
        "    img = Image.open(img_path)\n",
        "    height = img.size[1] # Image height\n",
        "    width = img.size[0] # Image width\n",
        "    #filename = img_path # Filename of the image. Empty if image is not from file\n",
        "    filename = b'' # Filename of the image. Empty if image is not from file\n",
        "    encoded_image_data = None # Encoded image bytes\n",
        "    image_format = b'jpeg' # b'jpeg' or b'png'\n",
        "    \n",
        "    with tf.gfile.GFile(img_path,'rb') as fid:\n",
        "        encoded_image_data = fid.read()\n",
        "\n",
        "    xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
        "    xmaxs = [] # List of normalized right x coordinates in bounding box  (1 per box)\n",
        "    ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
        "    ymaxs = [] # List of normalized bottom y coordinates in bounding box (1 per box)\n",
        "    classes_text = [] # List of string class name of bounding box (1 per box)\n",
        "    classes = [] # List of integer class id of bounding box (1 per box)\n",
        "    \n",
        "    try:\n",
        "        tree = parse(xml_path)\n",
        "        elem = tree.getroot()\n",
        "    except ParseError:\n",
        "        return None\n",
        "\n",
        "    for obj in elem.getiterator(\"object\"):\n",
        "        name = obj.find(\"name\").text\n",
        "        bndbox = obj.find(\"bndbox\")\n",
        "        xmin = bndbox.find(\"xmin\").text\n",
        "        xmax = bndbox.find(\"xmax\").text\n",
        "        ymin = bndbox.find(\"ymin\").text\n",
        "        ymax = bndbox.find(\"ymax\").text\n",
        "        classes_text.append(name.encode())\n",
        "        classes.append(class_list[name][\"id\"])\n",
        "        xmins.append(float(xmin) / width)\n",
        "        ymins.append(float(ymin) / height)\n",
        "        xmaxs.append(float(xmax) / width)\n",
        "        ymaxs.append(float(ymax) / height)\n",
        "        class_list[name][\"num\"] += 1\n",
        "\n",
        "    return create_tf_example(filename, width, height, \n",
        "                             encoded_image_data, image_format,\n",
        "                             xmins, xmaxs, ymins, ymaxs, classes_text, classes)\n",
        "\n",
        "def create_tf_example(filename, width, height, \n",
        "                      encoded_image_data, image_format, \n",
        "                      xmins, xmaxs, ymins, ymaxs, classes_text, classes):\n",
        "    \n",
        "     return tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image/height': dataset_util.int64_feature(height),\n",
        "      'image/width': dataset_util.int64_feature(width),\n",
        "      'image/filename': dataset_util.bytes_feature(filename),\n",
        "      'image/source_id': dataset_util.bytes_feature(filename),\n",
        "      'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
        "      'image/format': dataset_util.bytes_feature(image_format),\n",
        "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "\n",
        "from google.protobuf import text_format\n",
        "def create_labelmap(labels, output_path):\n",
        "    label_config = string_int_label_map_pb2.StringIntLabelMap()\n",
        "    for i,l in enumerate(labels):\n",
        "        item = label_config.item.add()\n",
        "        item.name = l\n",
        "        item.id = i+1\n",
        "        item.display_name = l\n",
        "    \n",
        "    labels_text = text_format.MessageToString(label_config)\n",
        "    with tf.gfile.Open(output_path, \"wb\") as f:\n",
        "        f.write(labels_text)\n",
        "        \n",
        "        \n",
        "print(\"TFRecord Util Define Done\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFRecord Util Define Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sc-oB7aYscm8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "使用するデータを指定する  \n",
        "dataset_typeには以下のいづれかの値を選んでください。  \n",
        "LabelBox: https://app.labelbox.com こちらで作ったもの  \n",
        "LabelImage: https://github.com/tzutalin/labelImg こちらで作ったもの  \n",
        "\n",
        "LabelBoxを選んだ場合はdataset_urlにcoco形式のJsonのURLを,   \n",
        "LabelImageを選んだ場合はセル実行後にzip or tar.gz形式のファイルをアップロードしてください"
      ]
    },
    {
      "metadata": {
        "id": "jwk42fuqsxiI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Set Dataset Dir {display-mode:\"form\"}\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "dataset_type = 'LabelBox' #@param ['LabelBox', 'LabelImage']\n",
        "\n",
        "dataset_url = 'https://storage.googleapis.com/labelbox-exports/cjudjh7vgc21b08714iykzgrd/cjudjhr0xbqvb0755f5ozh1j0/export-2019-04-12T11:23:55.020Z.json' #@param {type: \"string\"}\n",
        "dataset_dir = '' #@param {type: \"string\"}\n",
        "dataset_path = \"\\\"\" + dataset_dir + \"\\\"\"\n",
        "\n",
        "\n",
        "dataset_train_ratio = 85 #@param {type:\"slider\", min: 0, max:100}\n",
        "dataset_order = 'random' #@param ['random', 'date']\n",
        "\n",
        "if dataset_type == 'LabelImage':\n",
        "    !mkdir -p /content/dataset\n",
        "    print(\"copying files...\")\n",
        "    !rsync -az --info=progress2 $dataset_path /content/dataset\n",
        "    !echo \"copy files done!\"\n",
        "    %cd /content/dataset\n",
        "    files = glob.glob(\"/content/dataset/*.zip\", recursive=True)\n",
        "    for f in files:\n",
        "        print(\"unpacking...\")\n",
        "        shutil.unpack_archive(f)\n",
        "    labels = Util.GetLabels(\"/content/dataset\")\n",
        "    print(\"Labels: \")\n",
        "    print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xdPcf9iAVex0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "if there are any labeling misstakes use command '!find /content/dataset  -type f -name \\\"*.xml\\\" | xargs sed -i -e 's/before/after/g''"
      ]
    },
    {
      "metadata": {
        "id": "wPRBMQnq1XfK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習に必要なデータベースを作成する"
      ]
    },
    {
      "metadata": {
        "id": "qLy3n8eFUSeG",
        "colab_type": "code",
        "outputId": "5fed4f22-3d0b-4258-efcc-f111542a7c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Create TF Record {display-mode: \"form\"}\n",
        "\n",
        "!mkdir -p \"/content/tfrecords\"\n",
        "\n",
        "labels = []\n",
        "if dataset_type == \"LabelBox\":\n",
        "    labels = create_tf_record_labelBox(dataset_url, dataset_order, float(dataset_train_ratio)/100, \"/content/tfrecords\")\n",
        "    \n",
        "elif dataset_type == \"LabelImage\":\n",
        "   labels = create_tf_record_labelImage(\"/content/dataset\", dataset_order, float(dataset_train_ratio)/100, \"/content/tfrecords\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----Creating Train Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 939/939 [01:00<00:00, 13.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TFRecord convert done...939\n",
            "-----Label counts-----\n",
            "House: 1373\n",
            "Train: 1407\n",
            "Cloud: 1666\n",
            "River: 1662\n",
            "Heliport: 798\n",
            "Human: 1765\n",
            "----Creating Test Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 166/166 [00:10<00:00, 16.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TFRecord convert done...166\n",
            "-----Label counts-----\n",
            "House: 245\n",
            "Train: 243\n",
            "Cloud: 281\n",
            "River: 316\n",
            "Heliport: 128\n",
            "Human: 233\n",
            "TF Record Creation Complete.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wbKgtGd61mfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3. モデルを準備する"
      ]
    },
    {
      "metadata": {
        "id": "VYYEx2_21evv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このColaboratoryから使用できる学習済みモデルの一覧を表示します  \n",
        "Base Modelは下記に用意されているものhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md  \n",
        "\n",
        "model_dirを設定すると、そこに学習済みモデルがある場合Local Modelsに表示されます\n",
        "左のファイルツリーからパスをコピーしてください"
      ]
    },
    {
      "metadata": {
        "id": "eAhpxAGC3LuR",
        "colab_type": "code",
        "outputId": "113f1412-2d1f-42c7-a592-aa533cab1410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1073
        }
      },
      "cell_type": "code",
      "source": [
        "#@title List Available Models {display-mode: \"form\"}\n",
        "\n",
        "!mkdir -p /content/pretrained_model/ &> /dev/null\n",
        "%cd /content/pretrained_model \n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "#@markdown 既存のデータを使う場合は下記にGoogleDriveのパスを記入\n",
        "model_dir = '/content/drive/My Drive/PretrainedModels/Tensorflow' #@param {type: \"string\"}\n",
        "model_path = model_dir\n",
        "\n",
        "local_model_list = {}\n",
        "if os.path.exists(model_path):\n",
        "    gList = Util.GetAvailablePreTrains(model_path)\n",
        "    for i,g in enumerate(gList):\n",
        "        mName = os.path.basename(os.path.dirname(g['pipeline_path']))\n",
        "        local_model_list[mName] = os.path.dirname(g['pipeline_path'])\n",
        "\n",
        "r = requests.get(\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\")\n",
        "soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "base_model_list = {}\n",
        "for i,a in enumerate(soup.select('a[href^=\"http://download.tensorflow.org/models/object_detection/\"]')):\n",
        "    base_model_list[a.get_text()] = a.get('href')\n",
        "\n",
        "\n",
        "model_name = \"\"\n",
        "model_location = \"\"\n",
        "model_type = \"\"\n",
        "# Display List \n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "def set_model_list():\n",
        "    with output.redirect_to_element(\"#local-items\"):\n",
        "        for v,k in local_model_list.items():\n",
        "            li_elem = \"<li><ahref=\\\"javascript:void(0)\\\" onclick=\\\"setModel('{0}', '{1}')\\\">{0}</a></li>\".format(v, \"local\")\n",
        "            display(IPython.display.HTML(li_elem))\n",
        "            \n",
        "    with output.redirect_to_element(\"#base-items\"):\n",
        "        for v,k in base_model_list.items():\n",
        "            li_elem = \"<li><ahref=\\\"javascript:void(0)\\\" onclick=\\\"setModel('{0}', '{1}')\\\">{0}</a></li>\".format(v, \"base\")\n",
        "            display(IPython.display.HTML(li_elem))\n",
        "                                         \n",
        "def set_model(name,mtype):\n",
        "    global model_name, model_type, model_location\n",
        "    model_name = name\n",
        "    model_type = mtype\n",
        "    if mtype == \"local\":\n",
        "        model_location = local_model_list[name]\n",
        "    else:\n",
        "        model_location = base_model_list[name]\n",
        "    \n",
        "def get_model():\n",
        "    if model_type == \"local\":\n",
        "        shutil.copytree(model_location, \"/content/pretrained_model/%s\" % model_name)\n",
        "    else:\n",
        "        !wget $model_location &> /dev/null\n",
        "        !tar xzvf *.tar.gz &> /dev/null\n",
        "    print(\"Model preparation done.\")\n",
        "    \n",
        "output.register_callback('notebook.ShowModelList', set_model_list)\n",
        "output.register_callback('notebook.SetModel', set_model)\n",
        "output.register_callback('notebook.GetModel', get_model)\n",
        "display(IPython.display.HTML('''\n",
        "    <h3>Local Models:</h3>\n",
        "    <ol id=\"local-items\"></ol>\n",
        "    <h3>Base Models:</h3>\n",
        "    <ol id=\"base-items\"></ol>\n",
        "    <div>\n",
        "        Selected Model:<span id=\"model_name\"></span>\n",
        "    </div>\n",
        "    <button class=\"square_btn\" id=\"get-model-button\" onclick=\"getModel()\" disabled>Get Selected Model</button>\n",
        "    <style type=\"text/css\">\n",
        "    <!--\n",
        "    li {\n",
        "        color:blue; \n",
        "        line-height:1.5;\n",
        "        cursor : pointer;\n",
        "        text-decoration: underline;\n",
        "    }\n",
        "    .square_btn{\n",
        "        display: inline-block;\n",
        "        padding: 0.5em 1em;\n",
        "        text-decoration: none;\n",
        "        background: #668ad8;/*ボタン色*/\n",
        "        color: #FFF;\n",
        "        border-bottom: solid 4px #627295;\n",
        "        border-radius: 3px;\n",
        "    }\n",
        "    .square_btn:active {/*ボタンを押したとき*/\n",
        "        -ms-transform: translateY(4px);\n",
        "        -webkit-transform: translateY(4px);\n",
        "        transform: translateY(4px);/*下に動く*/\n",
        "        border-bottom: none;/*線を消す*/\n",
        "    }\n",
        "    -->\n",
        "    </style>\n",
        "    <script>\n",
        "        google.colab.kernel.invokeFunction('notebook.ShowModelList', [], {});\n",
        "        \n",
        "        function setModel(name,type) {\n",
        "            google.colab.kernel.invokeFunction('notebook.SetModel', [name, type], {});\n",
        "            document.getElementById(\"model_name\").innerHTML = name + \"(\"+type+\")\" \n",
        "            document.getElementById(\"get-model-button\").disabled = false\n",
        "        }\n",
        "        function getModel() {\n",
        "            google.colab.kernel.invokeFunction('notebook.GetModel', [], {});\n",
        "        }\n",
        "    </script>\n",
        "    '''))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pretrained_model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <h3>Local Models:</h3>\n",
              "    <ol id=\"local-items\"></ol>\n",
              "    <h3>Base Models:</h3>\n",
              "    <ol id=\"base-items\"></ol>\n",
              "    <div>\n",
              "        Selected Model:<span id=\"model_name\"></span>\n",
              "    </div>\n",
              "    <button class=\"square_btn\" id=\"get-model-button\" onclick=\"getModel()\" disabled>Get Selected Model</button>\n",
              "    <style type=\"text/css\">\n",
              "    <!--\n",
              "    li {\n",
              "        color:blue; \n",
              "        line-height:1.5;\n",
              "        cursor : pointer;\n",
              "        text-decoration: underline;\n",
              "    }\n",
              "    .square_btn{\n",
              "        display: inline-block;\n",
              "        padding: 0.5em 1em;\n",
              "        text-decoration: none;\n",
              "        background: #668ad8;/*ボタン色*/\n",
              "        color: #FFF;\n",
              "        border-bottom: solid 4px #627295;\n",
              "        border-radius: 3px;\n",
              "    }\n",
              "    .square_btn:active {/*ボタンを押したとき*/\n",
              "        -ms-transform: translateY(4px);\n",
              "        -webkit-transform: translateY(4px);\n",
              "        transform: translateY(4px);/*下に動く*/\n",
              "        border-bottom: none;/*線を消す*/\n",
              "    }\n",
              "    -->\n",
              "    </style>\n",
              "    <script>\n",
              "        google.colab.kernel.invokeFunction('notebook.ShowModelList', [], {});\n",
              "        \n",
              "        function setModel(name,type) {\n",
              "            google.colab.kernel.invokeFunction('notebook.SetModel', [name, type], {});\n",
              "            document.getElementById(\"model_name\").innerHTML = name + \"(\"+type+\")\" \n",
              "            document.getElementById(\"get-model-button\").disabled = false\n",
              "        }\n",
              "        function getModel() {\n",
              "            google.colab.kernel.invokeFunction('notebook.GetModel', [], {});\n",
              "        }\n",
              "    </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"5d5d1b30-5d16-11e9-9833-0242ac1c0002\"] = google.colab.output.getActiveOutputArea();\n",
              "//# sourceURL=js_0fd25083a2"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"5d5d5690-5d16-11e9-9833-0242ac1c0002\"] = document.querySelector(\"#local-items\");\n",
              "//# sourceURL=js_81e541baad"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"5d5dc544-5d16-11e9-9833-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"5d5d5690-5d16-11e9-9833-0242ac1c0002\"]);\n",
              "//# sourceURL=js_8327933575"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('big_tsumiki_20181122', 'local')\">big_tsumiki_20181122</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('big_tsumiki_20181210', 'local')\">big_tsumiki_20181210</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('big_tsumiki_20190411', 'local')\">big_tsumiki_20190411</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('sagaya_20181128', 'local')\">sagaya_20181128</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('sagaya_20181130', 'local')\">sagaya_20181130</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('sagaya_20191115', 'local')\">sagaya_20191115</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"5d60b376-5d16-11e9-9833-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"5d5d1b30-5d16-11e9-9833-0242ac1c0002\"]);\n",
              "//# sourceURL=js_362b3801d0"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"5d613c1a-5d16-11e9-9833-0242ac1c0002\"] = google.colab.output.getActiveOutputArea();\n",
              "//# sourceURL=js_1cd8d09073"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"5d61a7b8-5d16-11e9-9833-0242ac1c0002\"] = document.querySelector(\"#base-items\");\n",
              "//# sourceURL=js_22a6085d40"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"5d624efc-5d16-11e9-9833-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"5d61a7b8-5d16-11e9-9833-0242ac1c0002\"]);\n",
              "//# sourceURL=js_fc1e69a24a"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_coco', 'base')\">ssd_mobilenet_v1_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_0.75_depth_coco ☆', 'base')\">ssd_mobilenet_v1_0.75_depth_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_quantized_coco ☆', 'base')\">ssd_mobilenet_v1_quantized_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_0.75_depth_quantized_coco ☆', 'base')\">ssd_mobilenet_v1_0.75_depth_quantized_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_ppn_coco ☆', 'base')\">ssd_mobilenet_v1_ppn_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_fpn_coco ☆', 'base')\">ssd_mobilenet_v1_fpn_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_resnet_50_fpn_coco ☆', 'base')\">ssd_resnet_50_fpn_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v2_coco', 'base')\">ssd_mobilenet_v2_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v2_quantized_coco', 'base')\">ssd_mobilenet_v2_quantized_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssdlite_mobilenet_v2_coco', 'base')\">ssdlite_mobilenet_v2_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_inception_v2_coco', 'base')\">ssd_inception_v2_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_v2_coco', 'base')\">faster_rcnn_inception_v2_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet50_coco', 'base')\">faster_rcnn_resnet50_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet50_lowproposals_coco', 'base')\">faster_rcnn_resnet50_lowproposals_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('rfcn_resnet101_coco', 'base')\">rfcn_resnet101_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet101_coco', 'base')\">faster_rcnn_resnet101_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet101_lowproposals_coco', 'base')\">faster_rcnn_resnet101_lowproposals_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_resnet_v2_atrous_coco', 'base')\">faster_rcnn_inception_resnet_v2_atrous_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco', 'base')\">faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_nas', 'base')\">faster_rcnn_nas</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_nas_lowproposals_coco', 'base')\">faster_rcnn_nas_lowproposals_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('mask_rcnn_inception_resnet_v2_atrous_coco', 'base')\">mask_rcnn_inception_resnet_v2_atrous_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('mask_rcnn_inception_v2_coco', 'base')\">mask_rcnn_inception_v2_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('mask_rcnn_resnet101_atrous_coco', 'base')\">mask_rcnn_resnet101_atrous_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('mask_rcnn_resnet50_atrous_coco', 'base')\">mask_rcnn_resnet50_atrous_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet101_kitti', 'base')\">faster_rcnn_resnet101_kitti</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_resnet_v2_atrous_oidv2', 'base')\">faster_rcnn_inception_resnet_v2_atrous_oidv2</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_resnet_v2_atrous_lowproposals_oidv2', 'base')\">faster_rcnn_inception_resnet_v2_atrous_lowproposals_oidv2</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('facessd_mobilenet_v2_quantized_open_image_v4', 'base')\">facessd_mobilenet_v2_quantized_open_image_v4</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_resnet_v2_atrous_oidv4', 'base')\">faster_rcnn_inception_resnet_v2_atrous_oidv4</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenetv2_oidv4', 'base')\">ssd_mobilenetv2_oidv4</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_resnet_101_fpn_oidv4', 'base')\">ssd_resnet_101_fpn_oidv4</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet101_fgvc', 'base')\">faster_rcnn_resnet101_fgvc</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet50_fgvc', 'base')\">faster_rcnn_resnet50_fgvc</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet101_ava_v2.1', 'base')\">faster_rcnn_resnet101_ava_v2.1</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"5d6dc8ea-5d16-11e9-9833-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"5d613c1a-5d16-11e9-9833-0242ac1c0002\"]);\n",
              "//# sourceURL=js_f557d92c9b"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model preparation done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YKPmgDVTOGvf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4. 学習の設定をする"
      ]
    },
    {
      "metadata": {
        "id": "QTfSM-fPONrL",
        "colab_type": "code",
        "outputId": "bc7f0978-5e88-4c45-f6fd-52c106f60ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Prepare Run Config {display-mode:\"form\"}\n",
        "\n",
        "train_steps = 50000  #@param {type: \"number\"}\n",
        "eval_show_num = 30 #@param {type: \"number\"}\n",
        "eval_interval = 600 #@param {type: \"number\"}\n",
        "max_eval_num = 0 #@param {type: \"number\"}\n",
        "\n",
        "##########################################\n",
        "!mkdir -p /content/work\n",
        "#!mkdir -p /content/work/eval\n",
        "\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from object_detection.utils import config_util\n",
        "import glob\n",
        "\n",
        "models = Util.GetAvailablePreTrains(\"/content/pretrained_model\")\n",
        "\n",
        "config_path = \"/content/models/research/object_detection/samples/configs/\"+model_name +\".config\"\n",
        "\n",
        "if model_type == \"base\" and os.path.exists(config_path):\n",
        "    print(\"use samples/configs/**\")\n",
        "else:\n",
        "    print(\"use model included config\")\n",
        "    config_path = models[0]['pipeline_path']\n",
        "\n",
        "config = config_util.get_configs_from_pipeline_file(config_path)\n",
        "\n",
        "if(config['model'].HasField('ssd')):\n",
        "    config['model'].ssd.num_classes = len(labels)\n",
        "elif(config['model'].HasField('faster_rcnn')):\n",
        "    config['model'].faster_rcnn.num_classes = len(labels)\n",
        "\n",
        "config[\"train_config\"].fine_tune_checkpoint = models[0]['checkpoint_path']\n",
        "config[\"train_config\"].num_steps = train_steps\n",
        "config[\"train_input_config\"].label_map_path = \"/content/tfrecords/labelmap.pbtxt\"\n",
        "config[\"train_input_config\"].tf_record_input_reader.input_path.pop()\n",
        "train_files = glob.glob(\"/content/tfrecords/*train.record*\")\n",
        "for f in train_files:\n",
        "    config[\"train_input_config\"].tf_record_input_reader.input_path.append(f)\n",
        "    \n",
        "config[\"eval_input_config\"].label_map_path = \"/content/tfrecords/labelmap.pbtxt\"\n",
        "config[\"eval_input_config\"].tf_record_input_reader.input_path.pop()\n",
        "train_files = glob.glob(\"/content/tfrecords/*test.record*\")\n",
        "for f in train_files:\n",
        "    config[\"eval_input_config\"].tf_record_input_reader.input_path.append(f)\n",
        "    \n",
        "config['eval_config'].num_visualizations = eval_show_num\n",
        "config['eval_config'].max_evals = 0\n",
        "#config['eval_config'].visualization_export_dir = \"/content/work/eval\"\n",
        "#config['eval_config'].include_metrics_per_category = True\n",
        "config['eval_config'].eval_interval_secs = eval_interval\n",
        "#config['eval_config'].metrics_set.append('coco_detection_metrics')\n",
        "\n",
        "pipeline = config_util.create_pipeline_proto_from_configs(config)\n",
        "config_util.save_pipeline_config(pipeline, \"/content/work\")\n",
        "\n",
        "#!cat /content/work/pipeline.config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use model included config\n",
            "INFO:tensorflow:Writing pipeline config file to /content/work/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9W0Fcfvl0ZMC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "pipelineファイルの中身をみたければ...  \n",
        "!cat /content/work/pipeline.config  \n",
        "\n",
        "もしpipeline.configを手動でいじりたかったら、左のファイルリストから/work/pipeline.configをダウンロードして、上書きしてね\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "o_5sQLPY_Qbc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5. 学習の実行"
      ]
    },
    {
      "metadata": {
        "id": "qdUruAzl2NQI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習を監視するためのTensorboardを起動します"
      ]
    },
    {
      "metadata": {
        "id": "qnCkD79pybzX",
        "colab_type": "code",
        "outputId": "312be5f7-e502-47f7-cae6-d7cc0265b4f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Run Tensorboard {display-mode: \"form\"}\n",
        "import subprocess\n",
        "from subprocess import Popen\n",
        "from time import sleep \n",
        "\n",
        "#@markdown もしngrokのアカウントを持ってればtimeoutを回避できる(空白でも5時間は見れる)\n",
        "ngrok_token = '4hj8zDQwV1VS2YqeyjCCv_4cgo3nbXKa5VNs8NAbrg' #@param {type: \"string\"}\n",
        "\n",
        "res = subprocess.call('ps aux | grep tensorflow | grep -v grep', shell=True)\n",
        "if int(res) > 0:\n",
        "    print(\"tensorboard run...\")\n",
        "    cmd = \"tensorboard --logdir /content/work/ --host 0.0.0.0 --port 6006\"\n",
        "    proc = Popen( cmd,shell=True )\n",
        "else:\n",
        "    print(\"tensorboard already runing...\")\n",
        "\n",
        "sleep(5)\n",
        "\n",
        "!mkdir -p /content/ngrok\n",
        "%cd /content/ngrok\n",
        "res = subprocess.call('ps aux | grep ngrok | grep -v grep', shell=True)\n",
        "if int(res) > 0:\n",
        "    !rm -rf *\n",
        "    !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip &>/dev/null\n",
        "    !unzip *.zip &>/dev/null\n",
        "    print(\"ngrok run...\")\n",
        "    !./ngrok authtoken $ngrok_token\n",
        "    cmd = \"./ngrok http 6006\"\n",
        "    proc = Popen( cmd , shell=True)\n",
        "else:\n",
        "    print(\"ngrok already runing...\")\n",
        "\n",
        "sleep(5)\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import qrcode\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as npj\n",
        "import os.path\n",
        "\n",
        "res = requests.get('http://localhost:4040/api/tunnels')\n",
        "import re\n",
        "#print(res.text)\n",
        "m = re.search(r\"(https:\\/\\/.*?ngrok.io)\", res.text)\n",
        "if m:\n",
        "    print(\"Watch runing status bellow\")\n",
        "    url = m.group(1)\n",
        "    print(url)\n",
        "    img = qrcode.make(url)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorboard run...\n",
            "/content/ngrok\n",
            "ngrok run...\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
            "Watch runing status bellow\n",
            "https://d7723e69.ngrok.io\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_VGqLy6x2Uf_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "結果を出力するための場所を定義します  \n",
        "Google Driveを指定することで、Googleドライブに結果を出力できます"
      ]
    },
    {
      "metadata": {
        "id": "XBBmPIiMBKOW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Output Dir on Google Drive {display-mode:\"form\"}\n",
        "\n",
        "log_dir = '/content/drive/My Drive/PretrainedModels/Tensorflow/BigTsumiki/big_tsumiki_20190412' #@param {type: \"string\"}\n",
        "log_path = log_dir\n",
        "\n",
        "import os\n",
        "if not os.path.exists(log_path):\n",
        "    print(\"There is not such dir: %s\" % log_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xrAPDLFe2ifD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習を実行"
      ]
    },
    {
      "metadata": {
        "id": "3WNNj41XzR2O",
        "colab_type": "code",
        "outputId": "8ddb644e-b217-4992-dcca-a45e246a9a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4062
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Run Train {display-mode: \"form\"}\n",
        "from subprocess import Popen\n",
        "import subprocess\n",
        "\n",
        "res = subprocess.call('ps aux | grep rsync | grep -v grep', shell=True)\n",
        "if int(res) > 0:\n",
        "    cmd = \"/bin/bash -c 'while sleep 30; do rsync -a /content/work/* \\\"%s\\\"; done'\" % log_path\n",
        "    proc = Popen( cmd,shell=True )\n",
        "    print(\"rsync set /content/work/* to %s\" % log_path)\n",
        "\n",
        "%cd /content/models/research\n",
        "!python object_detection/model_main.py  \\\n",
        "            --pipeline_config_path=/content/work/pipeline.config \\\n",
        "            --model_dir=/content/work/log \\\n",
        "            --sample_1_of_n_eval_examples=1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rsync set /content/work/* to /content/drive/My Drive/PretrainedModels/Tensorflow/BigTsumiki/big_tsumiki_20190412\n",
            "/content/models/research\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f51c9913488>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:472: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:320: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:152: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2298: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:345: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "2019-04-12 11:31:37.453660: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2019-04-12 11:31:37.453931: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x20bed60 executing computations on platform Host. Devices:\n",
            "2019-04-12 11:31:37.453972: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-04-12 11:31:37.517278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-04-12 11:31:37.517870: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x20bf180 executing computations on platform CUDA. Devices:\n",
            "2019-04-12 11:31:37.517909: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-04-12 11:31:37.518286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 10.99GiB\n",
            "2019-04-12 11:31:37.518320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-12 11:31:37.876390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-12 11:31:37.876484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-12 11:31:37.876506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-12 11:31:37.876809: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-04-12 11:31:37.876869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10647 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-04-12 11:31:52.453037: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:785: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, use\n",
            "    tf.py_function, which takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    \n",
            "2019-04-12 11:41:59.798136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-12 11:41:59.798227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-12 11:41:59.798256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-12 11:41:59.798277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-12 11:41:59.798565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10647 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.51s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.904\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "2019-04-12 12:02:01.312123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-12 12:02:01.312208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-12 12:02:01.312239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-12 12:02:01.312258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-12 12:02:01.312501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10647 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.51s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.481\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.542\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.549\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "2019-04-12 12:12:00.926871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-12 12:12:00.926952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-12 12:12:00.926983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-12 12:12:00.927003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-12 12:12:00.927235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10647 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.49s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.916\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.554\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "2019-04-12 12:22:01.049575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-12 12:22:01.049659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-12 12:22:01.049702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-12 12:22:01.049721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-12 12:22:01.049965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10647 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.44s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.56s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.910\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "2019-04-12 12:32:00.529441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-12 12:32:00.529530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-12 12:32:00.529562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-12 12:32:00.529582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-12 12:32:00.529819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10647 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.51s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.915\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.510\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "2019-04-12 12:42:01.121169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-12 12:42:01.125454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-12 12:42:01.125490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-12 12:42:01.125510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-12 12:42:01.126857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10647 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.49s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.919\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.421\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uVJPtRMp9m7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 6. 学習データをエクスポートする"
      ]
    },
    {
      "metadata": {
        "id": "NdYwxuQ69sFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Export Graph {display-mode: \"form\"}\n",
        "\n",
        "#現在(2018/11/28)のObjectDetectionのサポートバージョンは1.9.0\n",
        "!pip install tensorflow==1.9.0 &> /dev/null\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from subprocess import Popen\n",
        "import subprocess\n",
        "\n",
        "res = subprocess.call('ps aux | grep rsync | grep -v grep', shell=True)\n",
        "if int(res) > 0:\n",
        "    cmd = \"/bin/bash -c 'while sleep 30; do rsync -a /content/work/* \\\"%s\\\"; done'\" % log_path\n",
        "    proc = Popen( cmd,shell=True )\n",
        "    print(\"rsync set /content/work/* to %s\" % log_path)\n",
        "\n",
        "%cd /content/models/research\n",
        "search_dir = \"/content/work/log/\"\n",
        "files = glob.glob(\"/content/work/log/model.ckpt-*.index\")\n",
        "files.sort(key=lambda x: os.path.getmtime(x))\n",
        "prefix = os.path.splitext(files[-1])[0]\n",
        "\n",
        "print(\"export checkpoint : %s\" % prefix )\n",
        "\n",
        "!rm -rf /content/work/export\n",
        "!cp -f /content/tfrecords/labelmap.pbtxt /content/work/\n",
        "!python object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=/content/work/pipeline.config \\\n",
        "    --trained_checkpoint_prefix=$prefix\\\n",
        "    --output_directory=/content/work/export"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6Ldtf9e-kHB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Appendix SandBox"
      ]
    },
    {
      "metadata": {
        "id": "3xcbWHhtSQWV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Change Tensorflow version {display-mode: \"form\"}\n",
        "import subprocess\n",
        "import re\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "res = subprocess.check_output(\"git ls-remote --tags https://github.com/tensorflow/tensorflow.git | awk '{print $2}'\", shell=True)\n",
        "tags = res.decode('utf-8').split(\"\\n\")\n",
        "\n",
        "versions = []\n",
        "for t in tags:\n",
        "    #print(t)\n",
        "    m = re.search(r\"v(1\\.[0-9]+\\.[0-9]+)$\", t)\n",
        "    if m:\n",
        "        versions.append(m.group(1))\n",
        "        \n",
        "versions.sort(key=lambda s: list(map(int, s.split('.'))))\n",
        "versions.reverse()\n",
        "\n",
        "def set_version_list():\n",
        "    with output.redirect_to_element(\"#version-list\"):\n",
        "        for i,v in enumerate(versions):\n",
        "            if i == 0:\n",
        "                radio_elem = \"<input type=\\\"radio\\\" name=\\\"version\\\" value=\\\"{0}\\\" checked />{0}\".format(v)\n",
        "            else:\n",
        "                radio_elem = \"<input type=\\\"radio\\\" name=\\\"version\\\" value=\\\"{0}\\\" />{0}\".format(v)\n",
        "            display(IPython.display.HTML(radio_elem))\n",
        "\n",
        "def change_version(version):\n",
        "    print(\"Changing tensorflow version to %s\" % version)\n",
        "    !pip install tensorflow==$version &> /dev/null\n",
        "    print(\"Change version completed\")\n",
        "\n",
        "output.register_callback('notebook.SetVersionList', set_version_list)\n",
        "output.register_callback('notebook.ChangeVersion', change_version)\n",
        "display(IPython.display.HTML('''\n",
        "    <h3>Change Tensorflow version:</h3>\n",
        "    <div id=\"version-list\">\n",
        "    </div>\n",
        "    <button class=\"square_btn\" id=\"change_btn\" onclick=\"changeVersion()\">Change Version</button>\n",
        "    <div id=\"debug\"></div>\n",
        "    <style type=\"text/css\">\n",
        "    <!--\n",
        "    .square_btn{\n",
        "        display: inline-block;\n",
        "        padding: 0.5em 1em;\n",
        "        text-decoration: none;\n",
        "        background: #668ad8;/*ボタン色*/\n",
        "        color: #FFF;\n",
        "        border-bottom: solid 4px #627295;\n",
        "        border-radius: 3px;\n",
        "    }\n",
        "    .square_btn:active {/*ボタンを押したとき*/\n",
        "        -ms-transform: translateY(4px);\n",
        "        -webkit-transform: translateY(4px);\n",
        "        transform: translateY(4px);/*下に動く*/\n",
        "        border-bottom: none;/*線を消す*/\n",
        "    }\n",
        "    -->\n",
        "    </style>\n",
        "    <script>\n",
        "        google.colab.kernel.invokeFunction('notebook.SetVersionList', [], {});\n",
        "        \n",
        "        function changeVersion() {\n",
        "            var elems = document.getElementsByName( \"version\" ) ;\n",
        "            for (var i=0; i<elems.length; i++) {\n",
        "\t           if ( elems[i].checked ) {\n",
        "                  google.colab.kernel.invokeFunction('notebook.ChangeVersion', [elems[i].value], {});\n",
        "\t\t          break ;\n",
        "\t           }\n",
        "            }\n",
        "        }\n",
        "    </script>\n",
        "    '''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a2EPra62-omN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#学習プロセスが動いているか確認\n",
        "!ps auxf | grep model_main | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7Z52C-p8qha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep tensorboard | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AhJyLky81xH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep ngrok | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p-wrWsKt-y-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#学習ログを削除\n",
        "!rm -rf /content/work/log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EAjRf11sgqwE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf /content/dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "domro3QMMDEB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!du -sh /content/tfrecords/*\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hEdPVsNuytWn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "23000 % 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CLMvduZkxQi8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf /content/dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HA7JBwwyNzwO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/work"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4OSXsp6vO2U8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}