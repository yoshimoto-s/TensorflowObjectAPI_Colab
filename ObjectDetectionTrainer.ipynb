{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetectionTrainer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoshimoto-s/TensorflowObjectAPI_Colab/blob/master/ObjectDetectionTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "y7w2BWvdbQgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Tensorflow Object Detection APIのトレーニングをするためのColabファイルです**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7kD7ccWxum8w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1. 環境の準備"
      ]
    },
    {
      "metadata": {
        "id": "ax29Z6Ha0rEt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "環境のチェック  \n",
        "[GPU OK] が出てくれば大丈夫！"
      ]
    },
    {
      "metadata": {
        "id": "ka9Qsd1UhdI8",
        "colab_type": "code",
        "outputId": "3f1d0c4b-b8ee-493f-f3d7-ba0deb3eed9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Check Environment {display-mode: \"form\"}\n",
        "\n",
        "#GPU環境の確認\n",
        "import platform\n",
        "print(\"python version: \"+platform.python_version())\n",
        "\n",
        "!pip install tensorflow  1>/dev/null\n",
        "#現在のObjectDetectionの対応Tensorflowは1.8らしいんだけど、1.8じゃうまく動かない...\n",
        "import tensorflow as tf;\n",
        "print(\"tensorflow version: \"+tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU not found')\n",
        "print('GPU OK')\n",
        "\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python version: 3.6.6\n",
            "tensorflow version: 1.12.0\n",
            "GPU OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L5M_bcGu05xf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "環境作成がうまく行ったか確認"
      ]
    },
    {
      "metadata": {
        "id": "jUtvgMXSiFUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title ObjectDetectionAPI Installation {display-mode: \"form\"}\n",
        "\n",
        "#install  env\n",
        "print(\"Dependency env installing...\")\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk 1>/dev/null\n",
        "!pip install Cython contextlib2 jupyter pillow lxml matplotlib 1>/dev/null\n",
        "!pip install prompt_toolkit==1.0.15 1>/dev/null\n",
        "\n",
        "%cd /content/\n",
        "#特定のコミットを使用する必要があるかもしれない(要検討)\n",
        "print(\"models cloning...\")\n",
        "!git clone https://github.com/tensorflow/models.git &> /dev/null\n",
        "\n",
        "#Cocoapi\n",
        "print(\"coco installing...\")\n",
        "!git clone https://github.com/cocodataset/cocoapi.git &> /dev/null\n",
        "%cd cocoapi/PythonAPI\n",
        "!make &>/dev/null\n",
        "!cp -r pycocotools /content/models/research/\n",
        "\n",
        "#compile protos\n",
        "print(\"proto compiling...\")\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "print(\"Set environ variables\")\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":\"+os.getcwd()\n",
        "os.environ['PYTHONPATH'] += \":\"+os.getcwd()+\"/slim\"\n",
        "\n",
        "print(\"Check environment\")\n",
        "!python object_detection/builders/model_builder_test.py\n",
        "\n",
        "\n",
        "### Other treatment\n",
        "!sed -i -e 's/category_index.values()/list(category_index.values())/' /content/models/research/object_detection/model_lib.py\n",
        "\n",
        "### Other requirment\n",
        "!pip install beautifulsoup4 requests 1>/dev/null\n",
        "!pip install qrcode 1>/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GmwV_HfwvBCb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2. データを準備する"
      ]
    },
    {
      "metadata": {
        "id": "fO5INN2D1OYU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "必要なUtilityを定義します"
      ]
    },
    {
      "metadata": {
        "id": "eM5KPlBZtwJw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Utility Config {display-mode: \"form\"}\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from xml.etree.ElementTree import *\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Util:\n",
        "    @staticmethod\n",
        "    def GetAvailablePreTrains(path):\n",
        "        graphInfoList = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f == 'pipeline.config':\n",
        "                    graphInfo = {}\n",
        "                    graphInfo['pipeline_path'] = os.path.join(root, f)\n",
        "                    ckpt_list = glob.glob(os.path.join(root, 'model.ckpt*.index'))\n",
        "                    if len(ckpt_list) > 0:\n",
        "                        ckpt_list.sort(key=lambda x: os.path.getmtime(x))\n",
        "                        ckpt_prefix = ckpt_list[-1][:-6]\n",
        "                        graphInfo['checkpoint_path'] = os.path.abspath(ckpt_prefix)\n",
        "                    else:\n",
        "                        ckpt_list = glob.glob(os.path.join(root, '*/model.ckpt*.index'))\n",
        "                        if len(ckpt_list) > 0:\n",
        "                            ckpt_list.sort(key=lambda x: os.path.getmtime(x))\n",
        "                            ckpt_prefix = ckpt_list[-1][:-6]\n",
        "                            graphInfo['checkpoint_path'] = os.path.abspath(ckpt_prefix)\n",
        "\n",
        "                    if('pipeline_path' in graphInfo and 'checkpoint_path' in graphInfo):\n",
        "                        graphInfoList.append(graphInfo)\n",
        "                        #print(\"==============\")\n",
        "                        #print(\"%d\\tpipeline_path:  \\t%s\" % (len(graphInfoList) - 1, graphInfo['pipeline_path']))\n",
        "                        #print(\"  \\tcheckpoint_path:\\t%s\" % (graphInfo['checkpoint_path']))\n",
        "        return graphInfoList\n",
        "\n",
        "    @staticmethod\n",
        "    def GetGraphList(path):\n",
        "        graphInfoList = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f == 'frozen_inference_graph.pb':\n",
        "                    graphInfo = {}\n",
        "                    graphInfo['graph_path'] = os.path.join(root, f)\n",
        "                    graphInfo['label_path'] = os.path.relpath(os.path.join(root, '../labelmap.pbtxt'))\n",
        "                    graphInfoList.append(graphInfo)\n",
        "                    print(\"==============\")\n",
        "                    print(\"%d\\tgraph_path:\\t%s\" % (len(graphInfoList) - 1, graphInfo['graph_path']))\n",
        "                    print(\"  \\tlabel_path:\\t%s\" % (graphInfo['label_path']))\n",
        "        return graphInfoList\n",
        "\n",
        "    @staticmethod\n",
        "    def GetLabels(path):\n",
        "        labels = []\n",
        "        xml_files = Util.GetXmlFiles(path)\n",
        "        for f in tqdm(xml_files):\n",
        "            tree = parse(f) \n",
        "            elem = tree.getroot()\n",
        "            for n in elem.findall(\".//name\"):\n",
        "                if n.text not in labels:\n",
        "                    labels.append(n.text)\n",
        "        print(\"\",flush=True)\n",
        "        return labels\n",
        "\n",
        "    @staticmethod\n",
        "    def GetXmlFiles(path):\n",
        "        xml_files = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f.lower().endswith('.xml'):\n",
        "                    xml_files.append(os.path.relpath(os.path.join(root,f)))\n",
        "        return xml_files\n",
        "\n",
        "    @staticmethod\n",
        "    def GetJPEGFiles(path):\n",
        "        jpg_files = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f.lower().endswith('.jpg'):\n",
        "                    jpg_files.append(os.path.relpath(os.path.join(root,f)))\n",
        "        return jpg_files\n",
        "    \n",
        "print(\"Util Define Done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GjTL2CMVERGX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title TFRecord Util {display-mode: \"form\"}\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from PIL import Image\n",
        "from xml.etree.ElementTree import *\n",
        "import time\n",
        "from object_detection.protos import string_int_label_map_pb2\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import json\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "\n",
        "#import contextlib2\n",
        "#from google3.third_party.tensorflow_models.object_detection.dataset_tools import tf_record_creation_util\n",
        "\n",
        "def create_tf_record_labelBox(json_url, order, train_ratio, output_path):\n",
        "    res = requests.get(json_url)\n",
        "    json_dict = json.loads(res.text)\n",
        "    categories = json_dict[\"categories\"]\n",
        "    labels = []\n",
        "    for cat in categories:\n",
        "        labels.append(cat[\"name\"])\n",
        "    images = json_dict[\"images\"]\n",
        "    annotations = json_dict[\"annotations\"]\n",
        "    if order == \"random\":\n",
        "        random.shuffle(images)\n",
        "    #elif oerder == \"date\":\n",
        "        #no operation\n",
        "    split_num = int(len(images) * train_ratio)\n",
        "    train_images = images[:split_num]\n",
        "    test_images = images[split_num:]\n",
        "    \n",
        "    print(\"\",flush=True)\n",
        "    print(\"----Creating Train Data\", flush=True)\n",
        "    create_tf_record_from_json_dict(train_images, annotations, labels, os.path.join(output_path,\"train.record\"))\n",
        "    print(\"----Creating Test Data\", flush=True)\n",
        "    create_tf_record_from_json_dict(test_images, annotations, labels, os.path.join(output_path,\"test.record\"))\n",
        "    create_labelmap(labels, os.path.join(output_path, \"labelmap.pbtxt\"))\n",
        "    print(\"TF Record Creation Complete.\")\n",
        "    \n",
        "def create_tf_record_from_json_dict(images, annotations, label_list, output_path):\n",
        "    class_list = {}\n",
        "    for i,l in enumerate(label_list):\n",
        "        class_list[l] = {\"id\":i+1, \"num\":0}\n",
        "    writer = tf.python_io.TFRecordWriter(output_path)\n",
        "    for img in tqdm(images):\n",
        "        id = img[\"id\"]\n",
        "        url = img[\"file_name\"]\n",
        "        width = int(img[\"width\"])\n",
        "        height = int(img[\"height\"])\n",
        "        res = requests.get(img[\"file_name\"])\n",
        "        encoded_image_data = res.content\n",
        "        filename = b''\n",
        "        image_format = b'jpeg'\n",
        "        \n",
        "        xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
        "        xmaxs = [] # List of normalized right x coordinates in bounding box  (1 per box)\n",
        "        ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
        "        ymaxs = [] # List of normalized bottom y coordinates in bounding box (1 per box)\n",
        "        classes_text = [] # List of string class name of bounding box (1 per box)\n",
        "        classes = [] # List of integer class id of bounding box (1 per box)\n",
        "        for anno in annotations:\n",
        "            if anno[\"image_id\"] == id:\n",
        "                xmins.append(float(anno[\"bbox\"][0]) / width)\n",
        "                ymins.append(float(anno[\"bbox\"][1]) / width)\n",
        "                xmaxs.append(float(anno[\"bbox\"][0] + anno[\"bbox\"][2]) / width)\n",
        "                ymaxs.append(float(anno[\"bbox\"][1] + anno[\"bbox\"][3]) / width)\n",
        "                name = label_list[int(anno[\"category_id\"]) -1]\n",
        "                classes_text.append(name.encode())\n",
        "                classes.append(class_list[name][\"id\"])\n",
        "                class_list[name][\"num\"] += 1\n",
        "                \n",
        "        tf_example = create_tf_example(filename, width, height, \n",
        "                             encoded_image_data, image_format,\n",
        "                             xmins, xmaxs, ymins, ymaxs, classes_text, classes)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "    writer.close()\n",
        "    \n",
        "    print(\"\",flush=True)\n",
        "    print(\"TFRecord convert done...%d\" % len(images)) \n",
        "    print(\"-----Label counts-----\")\n",
        "    for k,v in class_list.items():\n",
        "        print(k + \": \" + str(v[\"num\"]))\n",
        "    \n",
        "def create_tf_record_labelImage(input_dir, order, train_ratio, output_path): \n",
        "    xml_files = Util.GetXmlFiles(input_dir)\n",
        "    labels = Util.GetLabels(input_dir)\n",
        "    if order == \"random\":\n",
        "        random.shuffle(xml_files)\n",
        "    elif order == \"date\":\n",
        "        xml_files.sort(key=lambda f: int(filter(str.isdigit, os.path.basename(f))))\n",
        "    split_num = int(len(xml_files) * train_ratio)\n",
        "    train_xml_files = xml_files[:split_num]\n",
        "    test_xml_files = xml_files[split_num:]\n",
        "\n",
        "    print(\"\",flush=True)\n",
        "    print(\"----Creating Train Data\", flush=True)\n",
        "    create_tf_record_from_xml_list(train_xml_files, labels, os.path.join(output_path,\"train.record\"))\n",
        "    print(\"----Creating Test Data\", flush=True)\n",
        "    create_tf_record_from_xml_list(test_xml_files, labels, os.path.join(output_path, \"test.record\"))\n",
        "    create_labelmap(labels, os.path.join(output_path, \"labelmap.pbtxt\"))\n",
        "    print(\"TF Record Creation Complete.\", flush=True)\n",
        "\n",
        "def create_tf_record_from_xml_list(xml_list, label_list, output_path):\n",
        "    writer = tf.python_io.TFRecordWriter(output_path)\n",
        "    class_list = {}\n",
        "    for i,l in enumerate(label_list):\n",
        "        class_list[l] = {\"id\":i+1, \"num\":0}\n",
        "        \n",
        "    ignoreCount = 0\n",
        "    for f in tqdm(xml_list):\n",
        "        tf_example = create_tf_example_labelImage(f, class_list)\n",
        "        if(tf_example != None):\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "        else:\n",
        "            ignoreCount += 1\n",
        "    \n",
        "    writer.close()\n",
        "    print(\"\",flush=True)\n",
        "    print(\"TFRecord convert done...%d\" % len(xml_list)) \n",
        "    if ignoreCount > 0:\n",
        "        print(\"%d files ignored\" % ignoreCount)\n",
        "    print(\"-----Label counts-----\")\n",
        "    for k,v in class_list.items():\n",
        "        print(k + \": \" + str(v[\"num\"]))\n",
        "        \n",
        "    \n",
        "    #ここより先は気が向いたら実装する\n",
        "    #num_shards=10\n",
        "    #output_filebase='/path/to/train_dataset.record'\n",
        "\n",
        "    #with contextlib2.ExitStack() as tf_record_close_stack:\n",
        "        #output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
        "        #tf_record_close_stack, output_filebase, num_shards)\n",
        "        #for index, example in examples:\n",
        "            #tf_example = create_tf_example(example)\n",
        "            #output_shard_index = index % num_shards\n",
        "            #output_tfrecords[output_shard_index].write(tf_example.SerializeToString())\n",
        "    \n",
        "\n",
        "def create_tf_example_labelImage(xml_path,  class_list):\n",
        "    img_path = os.path.abspath(os.path.dirname(xml_path) + \"/../JPEGImages\") + \"/\" + os.path.basename(xml_path).replace('.xml','.jpg')\n",
        "    if(not os.path.exists(img_path)):\n",
        "        return None\n",
        "    \n",
        "    img = Image.open(img_path)\n",
        "    height = img.size[1] # Image height\n",
        "    width = img.size[0] # Image width\n",
        "    #filename = img_path # Filename of the image. Empty if image is not from file\n",
        "    filename = b'' # Filename of the image. Empty if image is not from file\n",
        "    encoded_image_data = None # Encoded image bytes\n",
        "    image_format = b'jpeg' # b'jpeg' or b'png'\n",
        "    \n",
        "    with tf.gfile.GFile(img_path,'rb') as fid:\n",
        "        encoded_image_data = fid.read()\n",
        "\n",
        "    xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
        "    xmaxs = [] # List of normalized right x coordinates in bounding box  (1 per box)\n",
        "    ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
        "    ymaxs = [] # List of normalized bottom y coordinates in bounding box (1 per box)\n",
        "    classes_text = [] # List of string class name of bounding box (1 per box)\n",
        "    classes = [] # List of integer class id of bounding box (1 per box)\n",
        "    \n",
        "    tree = parse(xml_path)\n",
        "    elem = tree.getroot()\n",
        "\n",
        "    for obj in elem.getiterator(\"object\"):\n",
        "        name = obj.find(\"name\").text\n",
        "        bndbox = obj.find(\"bndbox\")\n",
        "        xmin = bndbox.find(\"xmin\").text\n",
        "        xmax = bndbox.find(\"xmax\").text\n",
        "        ymin = bndbox.find(\"ymin\").text\n",
        "        ymax = bndbox.find(\"ymax\").text\n",
        "        classes_text.append(name.encode())\n",
        "        classes.append(class_list[name][\"id\"])\n",
        "        xmins.append(float(xmin) / width)\n",
        "        ymins.append(float(ymin) / height)\n",
        "        xmaxs.append(float(xmax) / width)\n",
        "        ymaxs.append(float(ymax) / height)\n",
        "        class_list[name][\"num\"] += 1\n",
        "\n",
        "    return create_tf_example(filename, width, height, \n",
        "                             encoded_image_data, image_format,\n",
        "                             xmins, xmaxs, ymins, ymaxs, classes_text, classes)\n",
        "\n",
        "def create_tf_example(filename, width, height, \n",
        "                      encoded_image_data, image_format, \n",
        "                      xmins, xmaxs, ymins, ymaxs, classes_text, classes):\n",
        "    \n",
        "     return tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image/height': dataset_util.int64_feature(height),\n",
        "      'image/width': dataset_util.int64_feature(width),\n",
        "      'image/filename': dataset_util.bytes_feature(filename),\n",
        "      'image/source_id': dataset_util.bytes_feature(filename),\n",
        "      'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
        "      'image/format': dataset_util.bytes_feature(image_format),\n",
        "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "\n",
        "from google.protobuf import text_format\n",
        "def create_labelmap(labels, output_path):\n",
        "    label_config = string_int_label_map_pb2.StringIntLabelMap()\n",
        "    for i,l in enumerate(labels):\n",
        "        item = label_config.item.add()\n",
        "        item.name = l\n",
        "        item.id = i+1\n",
        "        item.display_name = l\n",
        "    \n",
        "    labels_text = text_format.MessageToString(label_config)\n",
        "    with tf.gfile.Open(output_path, \"wb\") as f:\n",
        "        f.write(labels_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P59vjuno1RWl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Googleドライブをマウントする"
      ]
    },
    {
      "metadata": {
        "id": "TEt6sD37X1Sf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Mout Google Drive {display-mode: \"form\"}\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sc-oB7aYscm8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "使用するデータを指定する  \n",
        "dataset_typeには以下のいづれかの値を選んでください。  \n",
        "LabelBox: https://app.labelbox.com こちらで作ったもの  \n",
        "LabelImage: https://github.com/tzutalin/labelImg こちらで作ったもの  \n",
        "\n",
        "LabelBoxを選んだ場合はdataset_urlにcoco形式のJsonのURLを,   \n",
        "LabelImageを選んだ場合はdataset_dirにデータが格納されているGoogle Driveのパスを指定してください  \n",
        "GoogleDriveのパスは左のファイルツリーからで右クリック→パスをコピーしてください"
      ]
    },
    {
      "metadata": {
        "id": "jwk42fuqsxiI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Set Dataset Dir {display-mode:\"form\"}\n",
        "\n",
        "dataset_type = 'LabelBox' #@param ['LabelBox', 'LabelImage']\n",
        "\n",
        "dataset_url = '' #@param {type: \"string\"}\n",
        "dataset_dir = '' #@param {type: \"string\"}\n",
        "\n",
        "dataset_path = '\"/content/'+dataset_dir + '\"'\n",
        "\n",
        "dataset_order = 'random' #@param ['random', 'name']\n",
        "dataset_train_ratio = 80 #@param {type:\"slider\", min: 0, max:100}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPRBMQnq1XfK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習に必要なデータベースを作成する"
      ]
    },
    {
      "metadata": {
        "id": "qLy3n8eFUSeG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Create TF Record {display-mode: \"form\"}\n",
        "\n",
        "!mkdir -p \"/content/tfrecords\"\n",
        "\n",
        "if dataset_type == \"LabelBox\":\n",
        "    create_tf_record_labelBox(dataset_url, dataset_order, float(dataset_train_ratio)/100, \"/content/tfrecords\")\n",
        "    \n",
        "elif dataset_type == \"LabelImage\":\n",
        "    print(\"copying files...\")\n",
        "    !rsync -az --info=progress2 $dataset_path /content/dataset\n",
        "    !echo \"copy files done!\"\n",
        "    labels = Util.GetLabels(\"/content/dataset\")\n",
        "    print(\"Labels: \")\n",
        "    print(labels)\n",
        "    print(\"if there are ayn labeling misstakes use command '!find /content/dataset  -type f -name \\\"*.xml\\\" | xargs sed -i -e 's/before/after/g''\")\n",
        "    \n",
        "    create_tf_record_labelImage(\"/content/dataset\", dataset_order, float(dataset_train_ratio)/100, \"/content/tfrecords\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wbKgtGd61mfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3. モデルを準備する"
      ]
    },
    {
      "metadata": {
        "id": "VYYEx2_21evv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このColaboratoryから使用できる学習済みモデルの一覧を表示します  \n",
        "Base Modelは下記に用意されているものhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md  \n",
        "\n",
        "model_dirを設定すると、そこに学習済みモデルがある場合Local Modelsに表示されます"
      ]
    },
    {
      "metadata": {
        "id": "eAhpxAGC3LuR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title List Available Models {display-mode: \"form\"}\n",
        "\n",
        "!mkdir -p /content/pretrained_model/ &> /dev/null\n",
        "%cd /content/pretrained_model \n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "#@markdown 既存のデータを使う場合は下記にGoogleDriveのパスを記入\n",
        "model_dir = 'drive/My Drive/Training' #@param {type: \"string\"}\n",
        "model_path = \"/content/\" + model_dir\n",
        "\n",
        "local_model_list = {}\n",
        "if os.path.exists(model_path):\n",
        "    gList = Util.GetAvailablePreTrains(model_path)\n",
        "    for i,g in enumerate(gList):\n",
        "        mName = os.path.basename(os.path.dirname(g['pipeline_path']))\n",
        "        local_model_list[mName] = os.path.dirname(g['pipeline_path'])\n",
        "\n",
        "r = requests.get(\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\")\n",
        "soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "base_model_list = {}\n",
        "for i,a in enumerate(soup.select('a[href^=\"http://download.tensorflow.org/models/object_detection/\"]')):\n",
        "    base_model_list[a.get_text()] = a.get('href')\n",
        "\n",
        "\n",
        "model_name = \"\"\n",
        "model_location = \"\"\n",
        "model_type = \"\"\n",
        "# Display List \n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "def set_model_list():\n",
        "    with output.redirect_to_element(\"#local-items\"):\n",
        "        for v,k in local_model_list.items():\n",
        "            li_elem = \"<li><ahref=\\\"javascript:void(0)\\\" onclick=\\\"setModel('{0}', '{1}')\\\">{0}</a></li>\".format(v, \"local\")\n",
        "            display(IPython.display.HTML(li_elem))\n",
        "            \n",
        "    with output.redirect_to_element(\"#base-items\"):\n",
        "        for v,k in base_model_list.items():\n",
        "            li_elem = \"<li><ahref=\\\"javascript:void(0)\\\" onclick=\\\"setModel('{0}', '{1}')\\\">{0}</a></li>\".format(v, \"base\")\n",
        "            display(IPython.display.HTML(li_elem))\n",
        "                                         \n",
        "def set_model(name,mtype):\n",
        "    global model_name, model_type, model_location\n",
        "    model_name = name\n",
        "    model_type = mtype\n",
        "    if mtype == \"local\":\n",
        "        model_location = local_model_list[name]\n",
        "    else:\n",
        "        model_location = base_model_list[name]\n",
        "    \n",
        "def get_model():\n",
        "    if model_type == \"local\":\n",
        "        shutil.copytree(model_location, \"/content/pretrained_model/%s\" % model_name)\n",
        "    else:\n",
        "        !wget $model_location &> /dev/null\n",
        "        !tar xzvf *.tar.gz &> /dev/null\n",
        "    print(\"Model preparation done.\")\n",
        "    \n",
        "output.register_callback('notebook.ShowModelList', set_model_list)\n",
        "output.register_callback('notebook.SetModel', set_model)\n",
        "output.register_callback('notebook.GetModel', get_model)\n",
        "display(IPython.display.HTML('''\n",
        "    <h3>Local Models:</h3>\n",
        "    <ol id=\"local-items\"></ol>\n",
        "    <h3>Base Models:</h3>\n",
        "    <ol id=\"base-items\"></ol>\n",
        "    <div>\n",
        "        Selected Model:<span id=\"model_name\"></span>\n",
        "    </div>\n",
        "    <button id=\"get-model-button\" onclick=\"getModel()\" disabled>Get Selected Model</button>\n",
        "    <style type=\"text/css\">\n",
        "    <!--\n",
        "    li {color:blue; line-height:1.5;cursor : pointer;text-decoration: underline;}\n",
        "    -->\n",
        "    </style>\n",
        "    <script>\n",
        "        google.colab.kernel.invokeFunction('notebook.ShowModelList', [], {});\n",
        "        \n",
        "        function setModel(name,type) {\n",
        "            google.colab.kernel.invokeFunction('notebook.SetModel', [name, type], {});\n",
        "            document.getElementById(\"model_name\").innerHTML = name + \"(\"+type+\")\" \n",
        "            document.getElementById(\"get-model-button\").disabled = false\n",
        "        }\n",
        "        function getModel() {\n",
        "            google.colab.kernel.invokeFunction('notebook.GetModel', [], {});\n",
        "        }\n",
        "    </script>\n",
        "    '''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YKPmgDVTOGvf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4. 学習の設定をする"
      ]
    },
    {
      "metadata": {
        "id": "QTfSM-fPONrL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Prepare Run Config {display-mode:\"form\"}\n",
        "\n",
        "!mkdir -p /content/work\n",
        "\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from object_detection.utils import config_util\n",
        "\n",
        "models = Util.GetAvailablePreTrains(\"/content/pretrained_model\")\n",
        "\n",
        "config_path = \"/content/models/research/object_detection/samples/configs/\"+model_name +\".config\"\n",
        "\n",
        "if model_type == \"base\" and os.path.exists(config_path):\n",
        "    print(\"use samples/configs/**\")\n",
        "else:\n",
        "    print(\"use model included config\")\n",
        "    config_path = models[0]['pipeline_path']\n",
        "\n",
        "config = config_util.get_configs_from_pipeline_file(config_path)\n",
        "\n",
        "if(config['model'].HasField('ssd')):\n",
        "    config['model'].ssd.num_classes = len(labels)\n",
        "elif(config['model'].HasField('faster_rcnn')):\n",
        "    config['model'].faster_rcnn.num_classes = len(labels)\n",
        "\n",
        "config[\"train_config\"].fine_tune_checkpoint = models[0]['checkpoint_path']\n",
        "config[\"train_input_config\"].label_map_path = \"/content/tfrecords/labelmap.pbtxt\"\n",
        "config[\"train_input_config\"].tf_record_input_reader.input_path.pop()\n",
        "config[\"train_input_config\"].tf_record_input_reader.input_path.append(\"/content/tfrecords/train.record\")\n",
        "config[\"eval_input_config\"].label_map_path = \"/content/tfrecords/labelmap.pbtxt\"\n",
        "config[\"eval_input_config\"].tf_record_input_reader.input_path.pop()\n",
        "config[\"eval_input_config\"].tf_record_input_reader.input_path.append(\"/content/tfrecords/test.record\")\n",
        "\n",
        "pipeline = config_util.create_pipeline_proto_from_configs(config)\n",
        "config_util.save_pipeline_config(pipeline, \"/content/work\")\n",
        "\n",
        "#!cat /content/work/pipeline.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9W0Fcfvl0ZMC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "pipelineファイルの中身をみたければ...  \n",
        "!cat /content/work/pipeline.config  \n",
        "\n",
        "もしpipeline.configを手動でいじりたかったら、左のファイルリストから/work/pipeline.configをダウンロードして、上書きしてね\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "o_5sQLPY_Qbc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5. 学習の実行"
      ]
    },
    {
      "metadata": {
        "id": "qdUruAzl2NQI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習を監視するためのTensorboardを起動します"
      ]
    },
    {
      "metadata": {
        "id": "qnCkD79pybzX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Run Tensorboard {display-mode: \"form\"}\n",
        "from subprocess import Popen\n",
        "from time import sleep \n",
        "\n",
        "print(\"tensorboard run...\")\n",
        "cmd = \"tensorboard --logdir /content/work/ --host 0.0.0.0 --port 6006\"\n",
        "proc = Popen( cmd,shell=True )\n",
        "#2重起動しない仕組みいれないとなー\n",
        "\n",
        "sleep(5)\n",
        "\n",
        "!mkdir -p /content/ngrok\n",
        "%cd /content/ngrok\n",
        "!rm -rf *\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip &>/dev/null\n",
        "!unzip *.zip &>/dev/null\n",
        "\n",
        "print(\"ngrok run...\")\n",
        "cmd = \"./ngrok http 6006\"\n",
        "proc = Popen( cmd , shell=True)\n",
        "#2重起動しない仕組みいれないとなー\n",
        "\n",
        "sleep(5)\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import qrcode\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as npj\n",
        "import os.path\n",
        "\n",
        "res = requests.get('http://localhost:4040')\n",
        "import re\n",
        "#print(res.text)\n",
        "m = re.search(r\"(https:\\/\\/.*?ngrok.io)\", res.text)\n",
        "if m:\n",
        "    print(\"Watch runing status bellow\")\n",
        "    url = m.group(1)\n",
        "    print(url)\n",
        "    img = qrcode.make(url)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_VGqLy6x2Uf_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "結果を出力するための場所を定義します  \n",
        "Google Driveを指定することで、Googleドライブに結果を出力できます"
      ]
    },
    {
      "metadata": {
        "id": "XBBmPIiMBKOW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Output Dir on Google Drive {display-mode:\"form\"}\n",
        "\n",
        "log_dir = 'drive/My Drive/Colab/TensorflowObjectDetection' #@param {type: \"string\"}\n",
        "log_path = \"/content/\"+log_dir\n",
        "\n",
        "import os\n",
        "if not os.path.exists(log_path):\n",
        "    print(\"There is not such dir: %s\" % log_path)\n",
        "\n",
        "#sync log data to google drive\n",
        "from subprocess import Popen\n",
        "cmd = \"/bin/bash -c 'while sleep 30; do rsync -a /content/work/* \\\"%s\\\"; done'\" % log_path\n",
        "proc = Popen( cmd,shell=True )\n",
        "print(\"rsync set /content/work/* to %s\" % log_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xrAPDLFe2ifD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習を実行"
      ]
    },
    {
      "metadata": {
        "id": "3WNNj41XzR2O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Run Train {display-mode: \"form\"}\n",
        "\n",
        "%cd /content/models/research\n",
        "!python object_detection/model_main.py  \\\n",
        "            --pipeline_config_path=/content/work/pipeline.config \\\n",
        "            --model_dir=/content/work/log \\\n",
        "            --num_train_steps=50000 \\\n",
        "            --sample_1_of_n_eval_examples=1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uVJPtRMp9m7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 6. 学習データをエクスポートする"
      ]
    },
    {
      "metadata": {
        "id": "NdYwxuQ69sFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Export Graph {display-mode: \"form\"}\n",
        "import glob\n",
        "import os\n",
        "\n",
        "%cd /content/models/research\n",
        "search_dir = \"/content/work/log/\"\n",
        "files = glob.glob(\"/content/work/log/model.ckpt-*.index\")\n",
        "files.sort(key=lambda x: os.path.getmtime(x))\n",
        "prefix = os.path.splitext(files[-1])[0]\n",
        "\n",
        "print(\"export checkpoint : %s\" % prefix )\n",
        "\n",
        "!rm -rf /content/work/export\n",
        "!cp -f /content/tfrecord/labelmap.pbtxt /content/work/\n",
        "!python object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=/content/work/pipeline.config \\\n",
        "    --trained_checkpoint_prefix=$prefix\\\n",
        "    --output_directory=/content/work/export"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6Ldtf9e-kHB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Appendix SandBox"
      ]
    },
    {
      "metadata": {
        "id": "a2EPra62-omN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#学習プロセスが動いているか確認\n",
        "!ps auxf | grep model_main | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7Z52C-p8qha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep tensorboard | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AhJyLky81xH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep ngrok | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p-wrWsKt-y-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#学習ログを削除\n",
        "!rm -rf /content/work/log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TU0nUbEewsv6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#rsyncが動いているか\n",
        "!ps aux | grep while"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pk5aswDEwvlP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}