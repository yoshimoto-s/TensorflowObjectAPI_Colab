{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetectionTrainer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoshimoto-s/TensorflowObjectAPI_Colab/blob/master/ObjectDetectionTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "y7w2BWvdbQgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Tensorflow Object Detection APIのトレーニングをするためのColabファイルです**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7kD7ccWxum8w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1. 環境の準備"
      ]
    },
    {
      "metadata": {
        "id": "ka9Qsd1UhdI8",
        "colab_type": "code",
        "outputId": "d16219a6-6119-41d6-ce49-bd1093e67f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Check Environment {display-mode: \"form\"}\n",
        "\n",
        "#GPU環境の確認\n",
        "import platform\n",
        "print(\"python version: \"+platform.python_version())\n",
        "\n",
        "!pip install tensorflow  1>/dev/null\n",
        "#現在のObjectDetectionの対応Tensorflowは1.8らしいんだけど、1.8じゃうまく動かない...\n",
        "import tensorflow as tf;\n",
        "print(\"tensorflow version: \"+tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU not found')\n",
        "print('GPU OK')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python version: 3.6.6\n",
            "tensorflow version: 1.12.0\n",
            "GPU OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jUtvgMXSiFUg",
        "colab_type": "code",
        "outputId": "cdf4cf22-d596-4b6c-ffc6-e26eb1fd3059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "#@title ObjectDetectionAPI Installation {display-mode: \"form\"}\n",
        "\n",
        "#install  env\n",
        "print(\"Dependency env installing...\")\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk 1>/dev/null\n",
        "!pip install Cython contextlib2 jupyter pillow lxml matplotlib 1>/dev/null\n",
        "!pip install prompt_toolkit==1.0.15 1>/dev/null\n",
        "\n",
        "%cd /content/\n",
        "#特定のコミットを使用する必要があるかもしれない(要検討)\n",
        "print(\"models cloning...\")\n",
        "!git clone https://github.com/tensorflow/models.git &> /dev/null\n",
        "\n",
        "#Cocoapi\n",
        "print(\"coco installing...\")\n",
        "!git clone https://github.com/cocodataset/cocoapi.git &> /dev/null\n",
        "%cd cocoapi/PythonAPI\n",
        "!make &>/dev/null\n",
        "!cp -r pycocotools /content/models/research/\n",
        "\n",
        "#compile protos\n",
        "print(\"proto compiling...\")\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "print(\"Set environ variables\")\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":\"+os.getcwd()\n",
        "os.environ['PYTHONPATH'] += \":\"+os.getcwd()+\"/slim\"\n",
        "\n",
        "print(\"Check environment\")\n",
        "!python object_detection/builders/model_builder_test.py\n",
        "\n",
        "\n",
        "### Other treatment\n",
        "!sed -i -e 's/category_index.values()/list(category_index.values())/' /content/models/research/object_detection/model_lib.py\n",
        "\n",
        "### Other requirment\n",
        "!pip install beautifulsoup4 requests 1>/dev/null\n",
        "!pip install qrcode 1>/dev/null"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dependency env installing...\n",
            "\u001b[31mipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.7 which is incompatible.\u001b[0m\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
            "/content\n",
            "models cloning...\n",
            "coco installing...\n",
            "/content/cocoapi/PythonAPI\n",
            "proto compiling...\n",
            "/content/models/research\n",
            "Set environ variables\n",
            "Check environment\n",
            "......................\n",
            "----------------------------------------------------------------------\n",
            "Ran 22 tests in 0.132s\n",
            "\n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GmwV_HfwvBCb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2. データを準備する"
      ]
    },
    {
      "metadata": {
        "id": "XgjeUmvhv2X0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Google Driveをマウントする"
      ]
    },
    {
      "metadata": {
        "id": "TEt6sD37X1Sf",
        "colab_type": "code",
        "outputId": "4bc59dd6-13b0-46d3-ea02-c365c8aa8ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Mout Google Drive {display-mode: \"form\"}\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sc-oB7aYscm8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "データを格納しているディレクトリを設定する"
      ]
    },
    {
      "metadata": {
        "id": "jwk42fuqsxiI",
        "colab_type": "code",
        "outputId": "fea4baff-941e-4603-cf70-3b6937a12eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Set Dataset Dir {display-mode:\"form\"}\n",
        "\n",
        "dataset_dir = 'drive/My Drive/\\u5DE8\\u5927\\u7A4D\\u307F\\u6728/\\u304A\\u53F0\\u5834\\u5B66\\u7FD2\\u30C6\\u3099\\u30FC\\u30BF/2018-05-23' #@param {type: \"string\"}\n",
        "dataset_path = \"/content/\"+dataset_dir\n",
        "\n",
        "import os\n",
        "print(\"copying files...\")\n",
        "os.environ['TF_DATASET_PATH'] = dataset_path\n",
        "!rsync -azP --info=progress2 \"$TF_DATASET_PATH\" /content/dataset\n",
        "!echo \"copy files done!\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "copying files...\n",
            "     59,539,796 100%   43.23kB/s    0:22:24 (xfr#4595, to-chk=0/4638)\n",
            "copy files done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H8P9jpRtCfiT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ユーティリティを定義する"
      ]
    },
    {
      "metadata": {
        "id": "eM5KPlBZtwJw",
        "colab_type": "code",
        "outputId": "e2de6380-9568-49be-ef87-32f1dd274bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Utility Config {display-mode: \"form\"}\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from xml.etree.ElementTree import *\n",
        "import time\n",
        "\n",
        "class Util:\n",
        "    @staticmethod\n",
        "    def GetAvailablePreTrains(path):\n",
        "        graphInfoList = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f == 'pipeline.config':\n",
        "                    graphInfo = {}\n",
        "                    graphInfo['pipeline_path'] = os.path.join(root, f)\n",
        "                    ckpt_list = glob.glob(os.path.join(root, 'model.ckpt*.index'))\n",
        "                    if len(ckpt_list) > 0:\n",
        "                        ckpt_list.sort(key=lambda x: os.path.getmtime(x))\n",
        "                        ckpt_prefix = ckpt_list[-1][:-6]\n",
        "                        graphInfo['checkpoint_path'] = os.path.abspath(ckpt_prefix)\n",
        "                    else:\n",
        "                        ckpt_list = glob.glob(os.path.join(root, '*/model.ckpt*.index'))\n",
        "                        if len(ckpt_list) > 0:\n",
        "                            ckpt_list.sort(key=lambda x: os.path.getmtime(x))\n",
        "                            ckpt_prefix = ckpt_list[-1][:-6]\n",
        "                            graphInfo['checkpoint_path'] = os.path.abspath(ckpt_prefix)\n",
        "\n",
        "                    if('pipeline_path' in graphInfo and 'checkpoint_path' in graphInfo):\n",
        "                        graphInfoList.append(graphInfo)\n",
        "                        #print(\"==============\")\n",
        "                        #print(\"%d\\tpipeline_path:  \\t%s\" % (len(graphInfoList) - 1, graphInfo['pipeline_path']))\n",
        "                        #print(\"  \\tcheckpoint_path:\\t%s\" % (graphInfo['checkpoint_path']))\n",
        "        return graphInfoList\n",
        "\n",
        "    @staticmethod\n",
        "    def GetGraphList(path):\n",
        "        graphInfoList = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f == 'frozen_inference_graph.pb':\n",
        "                    graphInfo = {}\n",
        "                    graphInfo['graph_path'] = os.path.join(root, f)\n",
        "                    graphInfo['label_path'] = os.path.relpath(os.path.join(root, '../labelmap.pbtxt'))\n",
        "                    graphInfoList.append(graphInfo)\n",
        "                    print(\"==============\")\n",
        "                    print(\"%d\\tgraph_path:\\t%s\" % (len(graphInfoList) - 1, graphInfo['graph_path']))\n",
        "                    print(\"  \\tlabel_path:\\t%s\" % (graphInfo['label_path']))\n",
        "        return graphInfoList\n",
        "\n",
        "    @staticmethod\n",
        "    def GetLabels(path):\n",
        "        labels = []\n",
        "        xml_files = Util.GetXmlFiles(path)\n",
        "        for i,f in enumerate(xml_files):\n",
        "            if i % 10 == 9 or (i + 1 == len(xml_files)):\n",
        "                print(\"\\r>> Analizing...%d/%d\" % (i + 1, len(xml_files)), end='', flush=True)\n",
        "            tree = parse(f) \n",
        "            elem = tree.getroot()\n",
        "            for n in elem.findall(\".//name\"):\n",
        "                if n.text not in labels:\n",
        "                    labels.append(n.text)\n",
        "        print(\"\")\n",
        "        return labels\n",
        "\n",
        "    @staticmethod\n",
        "    def GetXmlFiles(path):\n",
        "        xml_files = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f.lower().endswith('.xml'):\n",
        "                    xml_files.append(os.path.relpath(os.path.join(root,f)))\n",
        "        return xml_files\n",
        "\n",
        "    @staticmethod\n",
        "    def GetJPEGFiles(path):\n",
        "        jpg_files = []\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for f in files:\n",
        "                if f.lower().endswith('.jpg'):\n",
        "                    jpg_files.append(os.path.relpath(os.path.join(root,f)))\n",
        "        return jpg_files\n",
        "    \n",
        "print(\"Util Define Done\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Util Define Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xUhzIrSoCmBp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ラベル情報を取得する"
      ]
    },
    {
      "metadata": {
        "id": "MQI_V_USBRqy",
        "colab_type": "code",
        "outputId": "cd9922ba-28a7-4d0a-874b-05e7e0c98cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "labels = Util.GetLabels(\"/content/dataset\")\n",
        "\n",
        "print(\"elapsed_time:%.3f[sec]\" % (time.time() - start))\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Analizing...2254/2254\n",
            "elapsed_time:0.835[sec]\n",
            "['river', 'person', 'cloud', 'train', 'house', 'heliport']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "11kw0W0ICVNq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ラベリングのミスとかあったら、下記コマンドで一括修正する\n",
        "#!find /content/dataset  -type f -name \"*.xml\" | xargs sed -i -e 's/before/after/g'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uKqijCaYDbGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "データを学習用とテスト用に分ける"
      ]
    },
    {
      "metadata": {
        "id": "GjTL2CMVERGX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title TFRecord Util {display-mode: \"form\"}\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from PIL import Image\n",
        "from xml.etree.ElementTree import *\n",
        "import time\n",
        "from object_detection.protos import string_int_label_map_pb2\n",
        "#import contextlib2\n",
        "#from google3.third_party.tensorflow_models.object_detection.dataset_tools import tf_record_creation_util\n",
        "\n",
        "def create_tf_record(xml_list, class_list, output_path):\n",
        "    start = time.time()\n",
        "    writer = tf.python_io.TFRecordWriter(output_path)\n",
        "    class_num_list = {}\n",
        "    for cn in class_list:\n",
        "        class_num_list[cn] = 0\n",
        "    ignoreCount = 0;\n",
        "    for i,f in enumerate(xml_list):\n",
        "        if i % 10 == 9 or (i + 1 == len(xml_list)):\n",
        "            print(\"\\r>> Converting...%d/%d\" % (i + 1, len(xml_list)), end='', flush=True)\n",
        "            \n",
        "        tf_example = create_tf_example(f, class_list, class_num_list)\n",
        "        if(tf_example != None):\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "        else:\n",
        "            ignoreCount += 1\n",
        "    writer.close()\n",
        "    print(\"TFRecord convert done...%d\" % len(xml_list)) \n",
        "    if ignoreCount > 0:\n",
        "        print(\"%d files ignored\" % ignoreCount)\n",
        "    print(\"-----Label counts-----\")\n",
        "    for k,v in class_num_list.items():\n",
        "        print(k + \": \" + str(v))\n",
        "    elapsed_time = time.time() - start\n",
        "    print(\"elapsed_time:%.3f[sec]\" % elapsed_time)\n",
        "    \n",
        "    #ここより先は気が向いたら実装する\n",
        "    #num_shards=10\n",
        "    #output_filebase='/path/to/train_dataset.record'\n",
        "\n",
        "    #with contextlib2.ExitStack() as tf_record_close_stack:\n",
        "        #output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
        "        #tf_record_close_stack, output_filebase, num_shards)\n",
        "        #for index, example in examples:\n",
        "            #tf_example = create_tf_example(example)\n",
        "            #output_shard_index = index % num_shards\n",
        "            #output_tfrecords[output_shard_index].write(tf_example.SerializeToString())\n",
        "    \n",
        "\n",
        "def create_tf_example(xml_path, class_list, class_num_list):\n",
        "    img_path = os.path.abspath(os.path.dirname(xml_path) + \"/../JPEGImages\") + \"/\" + os.path.basename(xml_path).replace('.xml','.jpg')\n",
        "    if(not os.path.exists(img_path)):\n",
        "        return None\n",
        "    \n",
        "    img = Image.open(img_path)\n",
        "    height = img.size[1] # Image height\n",
        "    width = img.size[0] # Image width\n",
        "    #filename = img_path # Filename of the image. Empty if image is not from file\n",
        "    filename = b'' # Filename of the image. Empty if image is not from file\n",
        "    encoded_image_data = None # Encoded image bytes\n",
        "    image_format = b'jpeg' # b'jpeg' or b'png'\n",
        "    \n",
        "    with tf.gfile.GFile(img_path,'rb') as fid:\n",
        "        encoded_image_data = fid.read()\n",
        "    \n",
        "\n",
        "    xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
        "    xmaxs = [] # List of normalized right x coordinates in bounding box  (1 per box)\n",
        "    ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
        "    ymaxs = [] # List of normalized bottom y coordinates in bounding box (1 per box)\n",
        "    classes_text = [] # List of string class name of bounding box (1 per box)\n",
        "    classes = [] # List of integer class id of bounding box (1 per box)\n",
        "    \n",
        "    tree = parse(xml_path)\n",
        "    elem = tree.getroot()\n",
        "\n",
        "    for obj in elem.getiterator(\"object\"):\n",
        "        name = obj.find(\"name\").text\n",
        "        bndbox = obj.find(\"bndbox\")\n",
        "        xmin = bndbox.find(\"xmin\").text\n",
        "        xmax = bndbox.find(\"xmax\").text\n",
        "        ymin = bndbox.find(\"ymin\").text\n",
        "        ymax = bndbox.find(\"ymax\").text\n",
        "        classes_text.append(name.encode())\n",
        "        classes.append(class_list.index(name) + 1)\n",
        "        xmins.append(float(xmin) / width)\n",
        "        ymins.append(float(ymin) / height)\n",
        "        xmaxs.append(float(xmax) / width)\n",
        "        ymaxs.append(float(ymax) / height)\n",
        "        class_num_list[name] += 1\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image/height': dataset_util.int64_feature(height),\n",
        "      'image/width': dataset_util.int64_feature(width),\n",
        "      'image/filename': dataset_util.bytes_feature(filename),\n",
        "      'image/source_id': dataset_util.bytes_feature(filename),\n",
        "      'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
        "      'image/format': dataset_util.bytes_feature(image_format),\n",
        "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "from google.protobuf import text_format\n",
        "\n",
        "def create_labelmap(labels, output_path):\n",
        "    label_config = string_int_label_map_pb2.StringIntLabelMap()\n",
        "    for i,l in enumerate(labels):\n",
        "        item = label_config.item.add()\n",
        "        item.name = l\n",
        "        item.id = i+1\n",
        "        item.display_name = l\n",
        "    \n",
        "    labels_text = text_format.MessageToString(label_config)\n",
        "    with tf.gfile.Open(output_path, \"wb\") as f:\n",
        "        f.write(labels_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ErfT5WGtDW6r",
        "colab_type": "code",
        "outputId": "cc57308d-7a5e-476e-b7a1-9d594181ef6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "xml_files = Util.GetXmlFiles(\"/content/dataset\")\n",
        "\n",
        "#全体の80%を学習用、20%を評価用に使う\n",
        "train_data_rate = 0.8\n",
        "random.shuffle(xml_files)\n",
        "split_num = int(len(xml_files) * train_data_rate)\n",
        "train_xml_files = xml_files[:split_num]\n",
        "test_xml_files = xml_files[split_num:]\n",
        "\n",
        "!mkdir -p /content/tfrecords\n",
        "create_tf_record(train_xml_files, labels, \"/content/tfrecords/train.record\")\n",
        "create_tf_record(test_xml_files, labels, \"/content/tfrecords/test.record\")\n",
        "create_labelmap(labels, \"/content/tfrecords/labelmap.pbtxt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Converting...1803/1803TFRecord convert done...1803\n",
            "166 files ignored\n",
            "-----Label counts-----\n",
            "river: 1156\n",
            "person: 1137\n",
            "cloud: 1063\n",
            "train: 1065\n",
            "house: 996\n",
            "heliport: 764\n",
            "elapsed_time:2.032[sec]\n",
            ">> Converting...451/451TFRecord convert done...451\n",
            "40 files ignored\n",
            "-----Label counts-----\n",
            "river: 304\n",
            "person: 265\n",
            "cloud: 269\n",
            "train: 252\n",
            "house: 279\n",
            "heliport: 204\n",
            "elapsed_time:0.538[sec]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wbKgtGd61mfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3. モデルを準備する"
      ]
    },
    {
      "metadata": {
        "id": "L0j5ehSx-A1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "環境の準備"
      ]
    },
    {
      "metadata": {
        "id": "eAhpxAGC3LuR",
        "colab_type": "code",
        "outputId": "e0b36c7d-e3db-44de-bbe7-26f927629147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "cell_type": "code",
      "source": [
        "#@title List Available Models {display-mode: \"form\"}\n",
        "\n",
        "!mkdir -p /content/pretrained_model/ &> /dev/null\n",
        "%cd /content/pretrained_model \n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "#@markdown 既存のデータを使う場合は下記にGoogleDriveのパスを記入\n",
        "model_dir = 'drive/My Drive/Training' #@param {type: \"string\"}\n",
        "model_path = \"/content/\" + model_dir\n",
        "\n",
        "local_model_list = {}\n",
        "if os.path.exists(model_path):\n",
        "    gList = Util.GetAvailablePreTrains(model_path)\n",
        "    for i,g in enumerate(gList):\n",
        "        mName = os.path.basename(os.path.dirname(g['pipeline_path']))\n",
        "        local_model_list[mName] = os.path.dirname(g['pipeline_path'])\n",
        "\n",
        "r = requests.get(\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\")\n",
        "soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "base_model_list = {}\n",
        "for i,a in enumerate(soup.select('a[href^=\"http://download.tensorflow.org/models/object_detection/\"]')):\n",
        "    base_model_list[a.get_text()] = a.get('href')\n",
        "\n",
        "\n",
        "model_name = \"\"\n",
        "model_location = \"\"\n",
        "model_type = \"\"\n",
        "# Display List \n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "def set_model_list():\n",
        "    with output.redirect_to_element(\"#local-items\"):\n",
        "        for v,k in local_model_list.items():\n",
        "            li_elem = \"<li><ahref=\\\"javascript:void(0)\\\" onclick=\\\"setModel('{0}', '{1}')\\\">{0}</a></li>\".format(v, \"local\")\n",
        "            display(IPython.display.HTML(li_elem))\n",
        "            \n",
        "    with output.redirect_to_element(\"#base-items\"):\n",
        "        for v,k in base_model_list.items():\n",
        "            li_elem = \"<li><ahref=\\\"javascript:void(0)\\\" onclick=\\\"setModel('{0}', '{1}')\\\">{0}</a></li>\".format(v, \"base\")\n",
        "            display(IPython.display.HTML(li_elem))\n",
        "                                         \n",
        "def set_model(name,mtype):\n",
        "    global model_name, model_type, model_location\n",
        "    model_name = name\n",
        "    model_type = mtype\n",
        "    if mtype == \"local\":\n",
        "        model_location = local_model_list[name]\n",
        "    else:\n",
        "        model_location = base_model_list[name]\n",
        "    \n",
        "def get_model():\n",
        "    if model_type == \"local\":\n",
        "        shutil.copytree(model_location, \"/content/pretrained_model/%s\" % model_name)\n",
        "    else:\n",
        "        !wget $model_location &> /dev/null\n",
        "        !tar xzvf *.tar.gz &> /dev/null\n",
        "    print(\"Model preparation done.\")\n",
        "    \n",
        "output.register_callback('notebook.ShowModelList', set_model_list)\n",
        "output.register_callback('notebook.SetModel', set_model)\n",
        "output.register_callback('notebook.GetModel', get_model)\n",
        "display(IPython.display.HTML('''\n",
        "    <h3>Local Models:</h3>\n",
        "    <ol id=\"local-items\"></ol>\n",
        "    <h3>Base Models:</h3>\n",
        "    <ol id=\"base-items\"></ol>\n",
        "    <div>\n",
        "        Selected Model:<span id=\"model_name\"></span>\n",
        "    </div>\n",
        "    <button id=\"get-model-button\" onclick=\"getModel()\" disabled>Get Selected Model</button>\n",
        "    <style type=\"text/css\">\n",
        "    <!--\n",
        "    li {color:blue; line-height:1.5;cursor : pointer;text-decoration: underline;}\n",
        "    -->\n",
        "    </style>\n",
        "    <script>\n",
        "        google.colab.kernel.invokeFunction('notebook.ShowModelList', [], {});\n",
        "        \n",
        "        function setModel(name,type) {\n",
        "            google.colab.kernel.invokeFunction('notebook.SetModel', [name, type], {});\n",
        "            document.getElementById(\"model_name\").innerHTML = name + \"(\"+type+\")\" \n",
        "            document.getElementById(\"get-model-button\").disabled = false\n",
        "        }\n",
        "        function getModel() {\n",
        "            google.colab.kernel.invokeFunction('notebook.GetModel', [], {});\n",
        "        }\n",
        "    </script>\n",
        "    '''))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pretrained_model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <h3>Local Models:</h3>\n",
              "    <ol id=\"local-items\"></ol>\n",
              "    <h3>Base Models:</h3>\n",
              "    <ol id=\"base-items\"></ol>\n",
              "    <div>\n",
              "        Selected Model:<span id=\"model_name\"></span>\n",
              "    </div>\n",
              "    <button id=\"get-model-button\" onclick=\"getModel()\" disabled>Get Selected Model</button>\n",
              "    <style type=\"text/css\">\n",
              "    <!--\n",
              "    li {color:blue; line-height:1.5;cursor : pointer;text-decoration: underline;}\n",
              "    -->\n",
              "    </style>\n",
              "    <script>\n",
              "        google.colab.kernel.invokeFunction('notebook.ShowModelList', [], {});\n",
              "        \n",
              "        function setModel(name,type) {\n",
              "            google.colab.kernel.invokeFunction('notebook.SetModel', [name, type], {});\n",
              "            document.getElementById(\"model_name\").innerHTML = name + \"(\"+type+\")\" \n",
              "            document.getElementById(\"get-model-button\").disabled = false\n",
              "        }\n",
              "        function getModel() {\n",
              "            google.colab.kernel.invokeFunction('notebook.GetModel', [], {});\n",
              "        }\n",
              "    </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"b30d663e-ebc9-11e8-85c8-0242ac1c0002\"] = google.colab.output.getActiveOutputArea();\n",
              "//# sourceURL=js_262a870e9b"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"b30e07ce-ebc9-11e8-85c8-0242ac1c0002\"] = document.querySelector(\"#local-items\");\n",
              "//# sourceURL=js_0aba8a261a"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"b30ea6d4-ebc9-11e8-85c8-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"b30e07ce-ebc9-11e8-85c8-0242ac1c0002\"]);\n",
              "//# sourceURL=js_4e7db142b2"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_v2_coco_2018_01_28', 'local')\">faster_rcnn_inception_v2_coco_2018_01_28</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"b30fcd20-ebc9-11e8-85c8-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"b30d663e-ebc9-11e8-85c8-0242ac1c0002\"]);\n",
              "//# sourceURL=js_ecda4c06b3"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"b3104930-ebc9-11e8-85c8-0242ac1c0002\"] = google.colab.output.getActiveOutputArea();\n",
              "//# sourceURL=js_35e354f1a6"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"b310f83a-ebc9-11e8-85c8-0242ac1c0002\"] = document.querySelector(\"#base-items\");\n",
              "//# sourceURL=js_d83d24bf07"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"b3116de2-ebc9-11e8-85c8-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"b310f83a-ebc9-11e8-85c8-0242ac1c0002\"]);\n",
              "//# sourceURL=js_512be7d1cf"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_coco', 'base')\">ssd_mobilenet_v1_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_0.75_depth_coco ☆', 'base')\">ssd_mobilenet_v1_0.75_depth_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_quantized_coco ☆', 'base')\">ssd_mobilenet_v1_quantized_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_0.75_depth_quantized_coco ☆', 'base')\">ssd_mobilenet_v1_0.75_depth_quantized_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_ppn_coco ☆', 'base')\">ssd_mobilenet_v1_ppn_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v1_fpn_coco ☆', 'base')\">ssd_mobilenet_v1_fpn_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_resnet_50_fpn_coco ☆', 'base')\">ssd_resnet_50_fpn_coco ☆</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v2_coco', 'base')\">ssd_mobilenet_v2_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_mobilenet_v2_quantized_coco', 'base')\">ssd_mobilenet_v2_quantized_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssdlite_mobilenet_v2_coco', 'base')\">ssdlite_mobilenet_v2_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('ssd_inception_v2_coco', 'base')\">ssd_inception_v2_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_v2_coco', 'base')\">faster_rcnn_inception_v2_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet50_coco', 'base')\">faster_rcnn_resnet50_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet50_lowproposals_coco', 'base')\">faster_rcnn_resnet50_lowproposals_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('rfcn_resnet101_coco', 'base')\">rfcn_resnet101_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet101_coco', 'base')\">faster_rcnn_resnet101_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet101_lowproposals_coco', 'base')\">faster_rcnn_resnet101_lowproposals_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_resnet_v2_atrous_coco', 'base')\">faster_rcnn_inception_resnet_v2_atrous_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco', 'base')\">faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_nas', 'base')\">faster_rcnn_nas</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_nas_lowproposals_coco', 'base')\">faster_rcnn_nas_lowproposals_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('mask_rcnn_inception_resnet_v2_atrous_coco', 'base')\">mask_rcnn_inception_resnet_v2_atrous_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('mask_rcnn_inception_v2_coco', 'base')\">mask_rcnn_inception_v2_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('mask_rcnn_resnet101_atrous_coco', 'base')\">mask_rcnn_resnet101_atrous_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('mask_rcnn_resnet50_atrous_coco', 'base')\">mask_rcnn_resnet50_atrous_coco</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet101_kitti', 'base')\">faster_rcnn_resnet101_kitti</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_resnet_v2_atrous_oid', 'base')\">faster_rcnn_inception_resnet_v2_atrous_oid</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid', 'base')\">faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('facessd_mobilenet_v2_quantized_open_image_v4', 'base')\">facessd_mobilenet_v2_quantized_open_image_v4</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet101_fgvc', 'base')\">faster_rcnn_resnet101_fgvc</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet50_fgvc', 'base')\">faster_rcnn_resnet50_fgvc</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<li><ahref=\"javascript:void(0)\" onclick=\"setModel('faster_rcnn_resnet101_ava_v2.1', 'base')\">faster_rcnn_resnet101_ava_v2.1</a></li>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window[\"b31c42a8-ebc9-11e8-85c8-0242ac1c0002\"] = google.colab.output.setActiveOutputArea(window[\"b3104930-ebc9-11e8-85c8-0242ac1c0002\"]);\n",
              "//# sourceURL=js_c441cbd7db"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model preparation done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YKPmgDVTOGvf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4. 学習の設定をする"
      ]
    },
    {
      "metadata": {
        "id": "QTfSM-fPONrL",
        "colab_type": "code",
        "outputId": "9bc9c779-dca4-4a9f-f350-ceb75c5ddba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Prepare Run Config {display-mode:\"form\"}\n",
        "\n",
        "!mkdir -p /content/work\n",
        "\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from object_detection.utils import config_util\n",
        "\n",
        "models = Util.GetAvailablePreTrains(\"/content/pretrained_model\")\n",
        "\n",
        "config_path = \"/content/models/research/object_detection/samples/configs/\"+model_name +\".config\"\n",
        "\n",
        "if model_type == \"base\" and os.path.exists(config_path):\n",
        "    print(\"use samples/configs/**\")\n",
        "else:\n",
        "    print(\"use model included config\")\n",
        "    config_path = models[0]['pipeline_path']\n",
        "\n",
        "config = config_util.get_configs_from_pipeline_file(config_path)\n",
        "\n",
        "if(config['model'].HasField('ssd')):\n",
        "    config['model'].ssd.num_classes = len(labels)\n",
        "elif(config['model'].HasField('faster_rcnn')):\n",
        "    config['model'].faster_rcnn.num_classes = len(labels)\n",
        "\n",
        "config[\"train_config\"].fine_tune_checkpoint = models[0]['checkpoint_path']\n",
        "config[\"train_input_config\"].label_map_path = \"/content/tfrecords/labelmap.pbtxt\"\n",
        "config[\"train_input_config\"].tf_record_input_reader.input_path.pop()\n",
        "config[\"train_input_config\"].tf_record_input_reader.input_path.append(\"/content/tfrecords/train.record\")\n",
        "config[\"eval_input_config\"].label_map_path = \"/content/tfrecords/labelmap.pbtxt\"\n",
        "config[\"eval_input_config\"].tf_record_input_reader.input_path.pop()\n",
        "config[\"eval_input_config\"].tf_record_input_reader.input_path.append(\"/content/tfrecords/test.record\")\n",
        "\n",
        "pipeline = config_util.create_pipeline_proto_from_configs(config)\n",
        "config_util.save_pipeline_config(pipeline, \"/content/work\")\n",
        "\n",
        "#!cat /content/work/pipeline.config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use samples/configs/**\n",
            "INFO:tensorflow:Writing pipeline config file to /content/work/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J4exvljM5DPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#もしpipeline.configを手動でいじりたかったら、左のファイルリストから/work/pipeline.configをダウンロードして、上書きしてね"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o_5sQLPY_Qbc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5. 学習の実行"
      ]
    },
    {
      "metadata": {
        "id": "qnCkD79pybzX",
        "colab_type": "code",
        "outputId": "eaf9168c-b5cd-4d6f-d8c4-79ca59424930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Run Tensorboard {display-mode: \"form\"}\n",
        "from subprocess import Popen\n",
        "from time import sleep \n",
        "\n",
        "print(\"tensorboard run...\")\n",
        "cmd = \"tensorboard --logdir /content/work/ --host 0.0.0.0 --port 6006\"\n",
        "proc = Popen( cmd,shell=True )\n",
        "#2重起動しない仕組みいれないとなー\n",
        "\n",
        "sleep(5)\n",
        "\n",
        "!mkdir -p /content/ngrok\n",
        "%cd /content/ngrok\n",
        "!rm -rf *\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip &>/dev/null\n",
        "!unzip *.zip &>/dev/null\n",
        "\n",
        "print(\"ngrok run...\")\n",
        "cmd = \"./ngrok http 6006\"\n",
        "proc = Popen( cmd , shell=True)\n",
        "#2重起動しない仕組みいれないとなー\n",
        "\n",
        "sleep(5)\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import qrcode\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as npj\n",
        "import os.path\n",
        "\n",
        "res = requests.get('http://localhost:4040')\n",
        "import re\n",
        "#print(res.text)\n",
        "m = re.search(r\"(https:\\/\\/.*?ngrok.io)\", res.text)\n",
        "if m:\n",
        "    print(\"Watch runing status bellow\")\n",
        "    url = m.group(1)\n",
        "    print(url)\n",
        "    img = qrcode.make(url)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorboard run...\n",
            "/content/ngrok\n",
            "ngrok run...\n",
            "Watch runing status bellow\n",
            "https://cc8ccbad.ngrok.io\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAFNCAYAAAC5YlyiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6107c90c50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XBBmPIiMBKOW",
        "colab_type": "code",
        "outputId": "d0fb2985-80f8-43df-d3b2-91bf1a97f39a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Log Output Dir {display-mode:\"form\"}\n",
        "\n",
        "log_dir = 'drive/My Drive/Colab/TensorflowObjectDetection' #@param {type: \"string\"}\n",
        "log_path = \"/content/\"+log_dir\n",
        "\n",
        "import os\n",
        "if not os.path.exists(log_path):\n",
        "    print(\"There is not such dir: %s\" % log_path)\n",
        "\n",
        "#sync log data to google drive\n",
        "from subprocess import Popen\n",
        "cmd = \"/bin/bash -c 'while sleep 30; do rsync -a /content/work/* \\\"%s\\\"; done'\" % log_path\n",
        "proc = Popen( cmd,shell=True )\n",
        "print(\"rsync set to %s\" % log_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rsync set to /content/drive/My Drive/Colab/TensorflowObjectDetection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HZvFAgwqxrVs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習を実行！！"
      ]
    },
    {
      "metadata": {
        "id": "3WNNj41XzR2O",
        "colab_type": "code",
        "outputId": "979cbab0-7b17-4ffa-b61b-64d54e55cdf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6172
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "!python object_detection/model_main.py  \\\n",
        "            --pipeline_config_path=/content/work/pipeline.config \\\n",
        "            --model_dir=/content/work/log \\\n",
        "            --num_train_steps=50000 \\\n",
        "            --sample_1_of_n_eval_examples=1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "/content/models/research/object_detection/utils/visualization_utils.py:27: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"object_detection/model_main.py\", line 26, in <module>\n",
            "    from object_detection import model_lib\n",
            "  File \"/content/models/research/object_detection/model_lib.py\", line 27, in <module>\n",
            "    from object_detection import eval_util\n",
            "  File \"/content/models/research/object_detection/eval_util.py\", line 27, in <module>\n",
            "    from object_detection.metrics import coco_evaluation\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 20, in <module>\n",
            "    from object_detection.metrics import coco_tools\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 47, in <module>\n",
            "    from pycocotools import coco\n",
            "  File \"/content/models/research/pycocotools/coco.py\", line 49, in <module>\n",
            "    import matplotlib.pyplot as plt\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\", line 72, in <module>\n",
            "    from matplotlib.backends import pylab_setup\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1119 07:40:59.791736 140348192692096 tf_logging.py:125] Forced number of epochs for all eval validations to be 1.\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1119 07:40:59.792094 140348192692096 tf_logging.py:125] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fa4f42db7b8>) includes params argument, but params are not passed to Estimator.\n",
            "W1119 07:40:59.792741 140348192692096 tf_logging.py:125] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fa4f42db7b8>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1119 07:40:59.850353 140348192692096 tf_logging.py:125] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W1119 07:40:59.952190 140348192692096 tf_logging.py:125] From /content/models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1119 07:41:00.135898 140348192692096 tf_logging.py:125] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W1119 07:41:00.804636 140348192692096 tf_logging.py:125] From /content/models/research/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/heads/box_head.py:93: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W1119 07:41:05.094190 140348192692096 tf_logging.py:125] From /content/models/research/object_detection/predictors/heads/box_head.py:93: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2164: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W1119 07:41:05.165453 140348192692096 tf_logging.py:125] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2164: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:345: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W1119 07:41:07.160553 140348192692096 tf_logging.py:125] From /content/models/research/object_detection/core/losses.py:345: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "2018-11-19 07:41:16.356044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-11-19 07:41:16.356518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.00GiB\n",
            "2018-11-19 07:41:16.356562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 07:41:16.754357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 07:41:16.754438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 07:41:16.754471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 07:41:16.754759: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-11-19 07:41:16.754827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2018-11-19 07:51:37.648740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 07:51:37.648830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 07:51:37.648864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 07:51:37.648895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 07:51:37.649179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=5.69s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.18s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.812\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.454\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.598\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "2018-11-19 08:01:38.331267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 08:01:38.331435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 08:01:38.331495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 08:01:38.331553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 08:01:38.332011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.88s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.25s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.859\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.544\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.553\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.438\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.626\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "2018-11-19 08:11:37.810226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 08:11:37.810332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 08:11:37.810365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 08:11:37.810395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 08:11:37.810642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.48s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.21s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.878\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.581\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.578\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.637\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.552\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.675\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\n",
            "\n",
            "2018-11-19 08:21:37.766017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 08:21:37.766127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 08:21:37.766160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 08:21:37.766192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 08:21:37.766439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.21s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.542\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.894\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.598\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.557\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.683\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\n",
            "\n",
            "2018-11-19 08:31:38.308281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 08:31:38.308399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 08:31:38.308447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 08:31:38.308492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 08:31:38.308756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.37s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.902\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.608\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.657\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.579\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.688\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "2018-11-19 08:41:37.907507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 08:41:37.907591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 08:41:37.907647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 08:41:37.907697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 08:41:37.907965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.31s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.19s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.906\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.627\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.385\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.607\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.662\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "2018-11-19 08:51:38.417240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 08:51:38.417341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 08:51:38.417375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 08:51:38.417407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 08:51:38.417643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.40s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.21s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.913\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.399\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.670\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.577\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.696\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "\n",
            "\n",
            "2018-11-19 09:01:38.264466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 09:01:38.264553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 09:01:38.264587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 09:01:38.264619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 09:01:38.264876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.919\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.653\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.418\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.678\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.680\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.590\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.709\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "2018-11-19 09:11:39.081894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 09:11:39.082009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 09:11:39.082042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 09:11:39.082073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 09:11:39.082310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=5.72s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.18s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.920\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.659\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.675\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.678\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "2018-11-19 09:31:39.660027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-19 09:31:39.660115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-19 09:31:39.660148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-19 09:31:39.660180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-19 09:31:39.660405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "creating index...\n",
            "index created!\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.18s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.597\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.931\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.680\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.430\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.684\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.599\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.714\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6yX9UvdjC867",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#pipelineファイルの中身をみたければ...\n",
        "#!cat /content/work/pipeline.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uVJPtRMp9m7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 6. 学習データをエクスポートする"
      ]
    },
    {
      "metadata": {
        "id": "NdYwxuQ69sFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "search_dir = \"/content/work/log/\"\n",
        "files = filter(os.path.isfile, glob.glob(\"/content/work/log/model.ckpt*\"))\n",
        "files.sort(key=lambda x: os.path.getmtime(x))\n",
        "\n",
        "#!python object_detection/export_inference_graph.py \\\n",
        "#    --input_type=image_tensor \\\n",
        "#    --pipeline_config_path=/content/work/pipeline.config \\\n",
        "#    --trained_checkpoint_prefix= \\\n",
        "#    --output_directory=/content/work/export"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6Ldtf9e-kHB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Appendix SandBox"
      ]
    },
    {
      "metadata": {
        "id": "a2EPra62-omN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#学習プロセスが動いているか確認\n",
        "!ps auxf | grep model_main | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7Z52C-p8qha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep tensorboard | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AhJyLky81xH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep ngrok | grep -v grep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p-wrWsKt-y-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#学習ログを削除\n",
        "!rm -rf /content/work/log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bP4DNCrWPawi",
        "colab_type": "code",
        "outputId": "7f23a756-0f9e-4269-a08c-30d2a938c92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep while"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root        3818  0.0  0.0  34300  4716 ?        S    07:40   0:00 /bin/sh -c /bin/bash -c 'while sleep 30; do rsync -a /content/work/* \"/content/drive/My Drive/Colab/TensorflowObjectDetection\"; done'\n",
            "root        3819  0.0  0.0  39192  6384 ?        S    07:40   0:00 /bin/bash -c while sleep 30; do rsync -a /content/work/* \"/content/drive/My Drive/Colab/TensorflowObjectDetection\"; done\n",
            "root        3821  0.0  0.0  39192  6540 ?        S    07:40   0:00 /bin/bash -c ps aux | grep while\n",
            "root        3823  0.0  0.0  38572  5616 ?        S    07:40   0:00 grep while\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b9GUMZrN16ij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill -9 3515"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3nZCQBD24vhA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}